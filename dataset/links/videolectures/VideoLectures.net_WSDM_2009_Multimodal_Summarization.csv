Video_Presentation,Abstracts
http://videolectures.net/wsdm09_dean_cblirs/,"Building and operating large-scale information retrieval systems used by hundreds of millions of people around the world provides a number of interesting challenges. Designing such systems requires making complex design tradeoffs in a number of dimensions, including (a) the number of user queries that must be handled per second and the response latency to these requests, (b) the number and size of various corpora that are searched, (c) the latency and frequency with which documents are updated or added to the corpora, and (d) the quality and cost of the ranking algorithms that are used for retrieval. In this talk I'll discuss the evolution of Google's hardware infrastructure and information retrieval systems and some of the design challenges that arise from ever-increasing demands in all of these dimensions. I'll also describe how we use various pieces of distributed systems infrastructure when building these retrieval systems. Finally, I'll describe some future challenges and open research problems in this area."
http://videolectures.net/wsdm09_weikum_hsrnw/,"There are major trends to advance the functionality of search engines to a more expressive semantic level. This is enabled by employing large-scale information extraction of entities and relationships from semistructured as well as natural-language Web sources. In addition, harnessing Semantic-Web-style ontologies and reaching into Deep-Web sources can contribute towards a grand vision of turning the Web into a comprehensive knowledge base that can be efficiently searched with high precision. This talk presents ongoing research towards this objective, with emphasis on our work on the YAGO knowledge base and the NAGA search engine but also covering related projects. YAGO is a large collection of entities and relational facts that are harvested from Wikipedia and WordNet with high accuracy and reconciled into a consistent RDF-style ""semantic"" graph. For further growing YAGO from Web sources while retaining its high quality, pattern-based extraction is combined with logic-based consistency checking in a unified framework. NAGA provides graph-template-based search over this data, with powerful ranking capabilities based on a statistical language model for graphs. Advanced queries and the need for ranking approximate matches pose efficiency and scalability challenges that are addressed by algorithmic and indexing techniques. YAGO is publicly available and has been imported into various other knowledge-management projects including DBpedia. YAGO shares many of its goals and methodologies with parallel projects along related lines. These include Avatar, Cimple/DBlife, DBpedia, KnowItAll/TextRunner, Kylin/KOG, and the Libra technology (and more). Together they form an exciting trend towards providing comprehensive knowledge bases with semantic search capabilities."
http://videolectures.net/wsdm09_liu_ubgsea/,"This paper focuses on ‘user browsing graph’ which is constructed with users’ click-through behavior modeled with Web access logs. User browsing graph has recently been adopted to improve Web search performance and the initial study shows it is more reliable than hyperlink graph for inferring page importance. However, structure and evolution of the user browsing graph haven’t been fully studied and many questions remain to be answered. In this paper, we look into the structure of the user browsing graph and its evolution over time. We try to give a quantitative analysis on the difference in graph structure between hyperlink graph and user browsing graph, and then find out why link analysis algorithms perform better on the browsing graph. We also propose a method for combining user behavior information into hyper link graph. Experimental results show that user browsing graph and hyperlink graph share few links in common and a combination of these two graphs can gain good performance in quality estimation of pages."
http://videolectures.net/wsdm09_goncalves_rwwl/,"Analysis of aggregate Web traffic has shown that PageRank is a poor model of how people actually navigate the Web. Using the empirical traffic patterns generated by a thousand users over the course of two months, we characterize the properties of Web traffic that cannot be reproduced by Markovian models, in which destinations are independent of past decisions. In particular, we show that the diversity of sites visited by individual users is smaller and more broadly distributed than predicted by the PageRank model; that link traffic is more broadly distributed than predicted; and that the time between consecutive visits to the same site by a user is less broadly distributed than predicted. To account for these discrepancies, we introduce a more realistic navigation model in which agents maintain individual lists of bookmarks that are used as teleportation targets. The model can also account for branching, a traffic property caused by browser features such as tabs and the back button. The model reproduces aggregate traffic patterns such as site popularity, while also generating more accurate predictions of diversity, link traffic, and return time distributions. This model for the first time allows us to capture the extreme heterogeneity of aggregate traffic measurements while explaining the more narrowly focused browsing patterns of individual users."
http://videolectures.net/wsdm09_arikan_twt/,"Temporal expressions, such as between 1992 and 2000, are frequent across many kinds of documents. Text retrieval, though, treats them as common terms, thus ignoring their inherent semantics. For queries with a strong temporal component, such as U.S. president 1997, this leads to a decrease in retrieval effectiveness, since relevant documents (e.g., a biography of Bill Clinton containing the aforementioned temporal expression) can not be reliably matched to the query. We propose a novel approach, based on language models, to make temporal expressions first-class citizens of the retrieval model. In addition, we present experiments that show actual improvements in retrieval effectiveness."
http://videolectures.net/wsdm09_heymann_ccvt/,"Social cataloging sites—tagging systems where users tag books—provide us with a rare opportunity to contrast tags to other information organization systems. We contrast tags to a controlled vocabulary, the Library of Congress Subject Headings, which has been developed over several decades. We find that many of the keywords designated by tags and LCSH are similar or the same, but that usage of keywords by annotators is quite different."
http://videolectures.net/wsdm09_sun_sccst/,"Most studies on tags focus on collaborative tagging systems where each resource (e.g., article, photo) can be tagged by multiple users with multiple tags. The tag usage patterns in self-tagging systems where a resource (e.g., a blog post) can only be tagged by its owner, however, have not been well studied. From the tags assigned by bloggers to their own blog posts, we obtain interesting insights on tag distribution stability and tag clarity. We further discuss the meaning of tag co-occurrences in the context of blogs and argue that tag networks based on co-occurrence from self-tagging system needs to be interpreted differently than that in collaborative tagging systems."
http://videolectures.net/wsdm09_antonellis_twq/,"Web search queries capture the information need of search engine users. Search engines store these queries in their logs and analyze them to guide their search results. In this work, we argue that not only a search engine can benefit from data stored in these logs, but also the web users. We first show how clickthrough logs can be collected in a distributed fashion using the http referer field in web server access logs. We then perform a set of experiments to study the information value of search engine queries when treated as ""tags"" or ""labels"" for the web pages that both appear as a result and the user actually clicks on. We ask how much extra information these query tags provide for web pages by comparing them to tags from the del.icio.us bookmarking site and to the pagetext. We find that query tags can provide substantially many (on average 250 tags per URL), new tags (on average 125 tags per URL are not present in the pagetext) for a large fraction of the Web."
