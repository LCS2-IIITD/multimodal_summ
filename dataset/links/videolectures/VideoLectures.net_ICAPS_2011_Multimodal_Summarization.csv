Video_Presentation,Abstracts
http://videolectures.net/icaps2011_palacios_albore_planning/,"Conformant planning is the problem of finding a sequence of actions for achieving a goal in the presence of uncertainty in the initial state or in action effects. On the other hand, Contingent planning is concerned with the problem of achieving goals in the presence of incomplete information and sensing actions. Both problems have been approached as a path-finding problem in belief space where good belief representations and heuristics are critical for scaling up. In this tutorial, we present algorithms for both conformant and contingent planning that rely on translations to classical planning problems, solved by an off-the-shelf classical planner.  The first half of this 1.5 hours tutorial will be devoted to present translations from conformant planning (i.e. planning with incomplete information and no sensing) into classical planning. Compiled classical problems are solved by a classical planner, taking advantage of heuristics developed for classical planning: as long as heuristics for searching in belief space have not be as successful so far. On top such a translation was built the T0 conformant planner, best performer of conformant track at IPC 2006. These general translation schemes are sound and we establish the conditions under which such translations are also complete. Thus, we present the notion of conformant width, that characterize the size of classical translations that are guarantee to be complete.  In the second half of the tutorial, we will focus on how to build efficient action selection mechanisms for planning with sensing (contingent planning) on top of conformant planning translations. In fact, the ability to find conformant plans is needed in contingent settings where conformant situations constitute a special case. Planning with incomplete information and partial observability is the most complex setting for planning. We will show how to obtain a closed-loop algorithm for achieving the goal in planning with sensing, using a conformant translation. Also, we will introduce the notion of contingent width, similar to the former conformant width, to characterize contingent planning problems.  Finally, building on the same translations, we will show how to obtain robust fine-state controllers. Finite-state and memoryless controllers are simple action selection mechanisms widely used in domains such as videogames and mobile robotics. We show how to develop model-based method for deriving finite-state controllers automatically. In particular, the models represent a class of contingent problems where actions are deterministic and some fluents are observable. The problem of deriving a controller from such models is converted into a conformant planning problem that is solved using classical planners, taking advantage of a complete translation introduced before. All algorithms will be illustrated with examples.  We expect the tutorial to be interesting for general AI researchers, as we build on simple ideas that has been successful, and that we introduce step by step. We will discuss other similar approaches and their limits, e.g. how a representation affects heuristic search, to put the translations introduced into context."
http://videolectures.net/icaps2011_chitta_planning/,"Sachin Chitta is a research scientist at Willow Garage. He received a PhD from the Grasp Lab at the University of Pennsylvania in 2005 and was a post-doctoral fellow in the Grasp Lab prior to joining Willow Garage in 2007. He finished his B.Tech from IIT, Mumbai in 1999. He worked on the dynamics and control of modular locomotion systems as a graduate student. As a post-doc, he was a part of the Littledog project at Penn which aimed to design controllers for robotic walking over extremely rough terrain. Sachin also worked in the Modular Robotics Lab at Penn, developing interesting dynamic gaits for modular robots.  Sachin's current research interests are in motion planning, learning for manipulation and mobile manipulation. His current research goal is to make robots more capable, safer and easier to use for non-experts. He would like to close the loop between sensing and manipulation in real-world environments with a specific interest in realtime motion planning in dynamic environments. He works extensively on controllers for all parts of the robot and is particularly excited by the possibility of doing cool two arm mobile manipulation tasks. Sachin is also interested in robust and reliable grasping based on real world sensor data."
http://videolectures.net/icaps2011_sanner_rddl/,"RDDL is the Relational Dynamic Influence Diagram Language, the domain modeling language used in the ICAPS 2011 International Probabilistic Planning Competition. RDDL has been developed to compactly model real-world planning problems that use boolean, multi-valued, integer and continuous variables, unrestricted concurrency, non-fluents, probabilistic independence among complex effects (important for exogenous events), aggregation operators in addition to quantifiers, and partial observability. While RDDL addresses some of the probabilistic modeling limitations of PPDDL, it's deterministic subset also addresses some modeling limitations of PDDL (e.g., models needing nonlinear difference equations or unrestricted concurrency). This tutorial provides a general introduction to RDDL, it's semantics, and a number of detailed examples like elevator and traffic control to demonstrate it's expressive power. It also provides a brief introduction to the rddlsim software that permits the simulation, evaluation, and visualization of planners and planning domains."
http://videolectures.net/icaps2011_williams_uncertainty/,"Spoken dialog systems present a classic example of planning under uncertainty. In a spoken dialog system, a computer is trying to help a person accomplish something, using spoken language as the communication medium. A key challenge is that speech recognition errors are ubiquitous and impossible to detect reliably, so the state of the conversation can never be known with certainty. Another challenge is that people do not behave deterministically. Despite these challenges, the system must choose actions to make progress to a long term goal. As such, decision theory presents an attractive approach to building spoken dialog systems. Initial work on ""toy"" dialog systems validated benefits, but also found that straightforward formulations could not scale to real-world problems. Subsequent work by a number of research teams has shown how to scale to industrial-scale systems, how to incorporate high-fidelity user simulations, and how to synthesize commercial development practices with automatic optimization. This talk traces the evolution of this application of planning under uncertainty, comments on progress toward use in industry, and suggests future avenues of research relevant to researchers interested in planning under uncertainty."
http://videolectures.net/icaps2011_van_hentenryck_disaster/,"Every year, natural disasters cause infrastructure damages and power outages that have considerable impacts on both quality of life and economic welfare. Mitigating the effects of disasters is an important but challenging task, given the underlying uncertainty, the need for fast response, and the complexity and scale of the infrastructures involved, not to mention the social and policy issues. This talk describes how to use planning and scheduling technologies to address these challenges in a rigorous and principled way. In particular, we present the first optimization solutions to last-mile disaster preparedness and recovery for a single commodity (e.g., water) and for the electrical power network. The optimization algorithms were compared to existing practice on disaster scenarios based on the US infrastructure (at the state scale) and generated by state-of-the-art hurricane simulation tools. Some of our algorithms are deployed as part as the Los Alamos National Laboratories operational tools and provide recommendations to the U.S. Department of Homeland Security."
http://videolectures.net/icaps2011_wellman_game/,"The games agents play - in markets, conflicts, or most other contexts - often defy strict game-theoretic analysis. Games may be unmanageably large (combinatorial or infinite state or action spaces), and present severely imperfect information, which could be further complicated by partial dynamic revelation. Moreover, the game may be specified procedurally, for instance by a simulator, rather than in an explicit game form. With colleagues and students over the past few years, I have been developing a body of techniques for strategic analysis, adopting the game-theoretic framework but employing it in domains where direct ""model-and-solve"" cannot apply. This empirical game-theoretic methodology embraces simulation, approximation, statistics and learning, and search. Through applications to canonical auction games, and rich trading scenarios, we demonstrate the value of empirical methods for extending the scope of game-theoretic analysis. This perspective also sheds insight into behavioral models and bases for predicting joint action in complex multiagent scenarios."
http://videolectures.net/icaps2011_magazzeni_automatic/,"Efficient use of multiple batteries is a practical problem with wide and growing application. The problem can be cast as a planning problem. We describe the approach we have adopted to modelling and solving this problem, seen as a Markov Decision Problem, building effective policies for battery switching in the face of stochastic load profiles. Our solution exploits and adapts several existing techniques from the planning literature and leads to the construction of policies that significantly outperform those that are currently in use and the best published solutions to the battery management problem. We achieve solutions that achieve more than 99\% efficiency compared with the theoretical limit and do so with far fewer battery switches than existing policies. We describe the approach in detail and provide empirical evaluation demonstrating its effectiveness."
http://videolectures.net/icaps2011_planken_computing/,"Considering directed graphs on n vertices and m edges with real (possibly negative) weights, we present two new, efficient algorithms for computing all-pairs shortest paths (APSP). These algorithms make use of directed path consistency (DPC) along a vertex ordering d. The algorithms run in O(n2wd) time, where wd is the graph width induced by this vertex ordering. For graphs of constant tree width, this yields O(n2) time, which is optimal. On chordal graphs, the algorithms run in O(nm) time. We show empirically that also in many general cases, both constructed and from realistic benchmarks, the algorithms often outperform Johnson's algorithm, which represents the current state of the art with a run time of O(nm + n2log n). These algorithms can be used for temporal and spatial reasoning, e.g. for the Simple Temporal Problem (STP), which underlines its relevance to the planning and scheduling community."
http://videolectures.net/icaps2011_ramanujan_sampling/,"The Upper Confidence bounds for Trees (UCT) algorithm has in recent years captured the attention of the planning and game-playing community due to its notable success in the game of Go. However, attempts to reproduce similar levels of performance in domains that are the forte of Minimax-style algorithms have been largely unsuccessful, making any comparative studies of the two hard. In this paper, we study UCT in the game of Mancala, which to our knowledge is the first domain where both search algorithms perform quite well with minimal enhancement. We focus on the three key components of the UCT algorithm in its purest form - targeted node expansion, state value estimation via playouts and averaging backups - and look at their contributions to the overall performance of the algorithm. We study the trade-offs involved in using alternate ways to perform these steps. Finally, we demonstrate a novel hybrid approach to enhancing UCT, that exploits its superior decision accuracy in regions of the search space with few terminal nodes."
http://videolectures.net/icaps2011_velez_exploiting/,"Consider the task of a mobile robot autonomously navigating through an environment while detecting and mapping objects of interest using a noisy object detector. The robot must reach its destination in a timely manner, but is rewarded for correctly detecting recognizable objects to be added to the map, and penalized for false alarms. However, detector performance typically varies with vantage point, so the robot benefits from planning trajectories which maximize the efficacy of the recognition system. This work describes an online, any-time planning framework enabling the active exploration of possible detections provided by an off-the-shelf object detector. We present a probabilistic approach where vantage points are identified which provide a more informative view of a potential object. The agent then weighs the benefit of increasing its confidence against the cost of taking a detour to reach each identified vantage point. The system is demonstrated to significantly improve detection and trajectory length in both simulated and real robot experiments."
http://videolectures.net/icaps2011_kolobov_heuristic/,"Research in efficient methods for solving infinite-horizon MDPs has so far concentrated primarily on discounted MDPs and the more general stochastic shortest path problems (SSPs). These are MDPs with 1) an optimal value function V* that is the unique solution of Bellman equation and 2) optimal policies that are the greedy policies w.r.t. V*. This paper’s main contribution is the description of a new class of MDPs, that have well-defined optimal solutions that do not comply with either 1 or 2 above. We call our new class Generalized Stochastic Shortest Path (GSSP) problems. GSSP allows more general reward structure than SSP and subsumes several established MDP types including SSP, positive-bounded, negative, and discounted-reward models. While existing efficient heuristic search algorithms like LAO* and LRTDP are not guaranteed to converge to the optimal value function for GSSPs, we present a new heuristic-search-based family of algorithms, FRET (Find, Revise, Eliminate Traps). A preliminary empirical evaluation shows that FRET solves GSSPs much more efficiently than Value Iteration."
http://videolectures.net/icaps2011_lesner_probabilistic/,"We present a novel dynamic programming approach to computing optimal policies for Markov Decision Processes compactly represented in grounded Probabilistic PDDL. Unlike other approaches, which use an intermediate representation as Dynamic Bayesian Networks, we directly exploit the PPDDL description by introducing dedicated backup rules. This provides an alternative approach to DBNs, especially when actions have highly correlated effects on variables. Indeed, we show interesting improvements on several planning domains from the International Planning Competition. Finally, we exploit the incremental flavor of our backup rules for designing promising approaches to policy revision."
http://videolectures.net/icaps2011_poupart_solutions/,"POMDP algorithms have made significant progress in recent years by allowing practitioners to find good solutions to increasingly large problems. Most approaches (including point-based and policy iteration techniques) operate by refining a lower bound of the optimal value function. Several approaches (e.g., HSVI2, SARSOP, grid-based approaches and online forward search) also refine an upper bound. However, approximating the optimal value function by an upper bound is computationally expensive and therefore tightness is often sacrificed to improve efficiency (e.g., sawtooth approximation). In this paper, we describe a new approach to efficiently compute tighter bounds by i) conducting a prioritized breadth first search over the reachable beliefs, ii) propagating upper bound improvements with an augmented POMDP and iii) using exact linear programming (instead of the sawtooth approximation) for upper bound interpolation. As a result, we can represent the bounds more compactly and significantly reduce the gap between upper and lower bounds on several benchmark problems."
http://videolectures.net/icaps2011_weng_preferences/,"In a standard Markov decision process (MDP), rewards are assumed to be precisely known and of quantitative nature. This can be a too strong hypothesis in some situations. When rewards can really be modeled numerically, specifying the reward function is often difficult as it is a cognitively-demanding and/or time-consuming task. Besides, rewards can sometimes be of qualitative nature as when they represent qualitative risk levels for instance. In those cases, it is problematic to use directly standard MDPs and we propose instead to resort to MDPs with ordinal rewards. Only a total order over rewards is assumed to be known. In this setting, we explain how an alternative way to define expressive and interpretable preferences using reference points can be exploited."
http://videolectures.net/icaps2011_jonsson_planning/,"Multiagent planning is computationally hard in the general case due to the exponential blowup in the action space induced by concurrent action of different agents. At the same time, many scenarios require the computation of plans that are strategically meaningful for selfinterested agents, in order to ensure that there would be sufficient incentives for those agents to participate in a joint plan. In this paper, we present a multiagent planning and plan improvement method that is based on conducting iterative best-response planning using standard single-agent planning algorithms. In constrained types of planning scenarios that correspond to congestion games, this is guaranteed to converge to a plan that is a Nash equilibrium with regard to agents’ preference profiles over the entire plan space. Our empirical evaluation beyond these restricted scenarios shows, however, that the algorithm has much broader applicability as a method for plan improvement in general multiagent planning problems. Extensive empirical experiments in various domains illustrate the scalability of our method in both cases."
http://videolectures.net/icaps2011_srivastava_planners/,"We consider the problem of finding provably correct generalized plans for situations where the number of objects may be unknown and unbounded during planning. The input is a domain specification, a goal condition, and a class of concrete problem instances or initial states to be solved, expressed in an abstract first-order representation. Starting with an empty generalized plan, our overall approach is to incrementally increase the applicability of the plan by identifying a problem instance that it cannot solve, invoking a classical planner to solve that problem, generalizing the obtained solution and merging it back into the generalized plan. The main contributions of this paper are methods for (a) generating and solving small problem instances not yet covered by an existing generalized plan, (b) translating between concrete classical plans and abstract plan representations, and (c) extending partial generalized plans and increasing their applicability. We analyze the theoretical properties of these methods, prove their correctness, and illustrate experimentally their scalability. The resulting hybrid approach shows that solving only a few, small, classical planning problems can be sufficient to produce a generalized plan that applies to infinitely many problems with unknown numbers of objects."
http://videolectures.net/icaps2011_gerevini_planning/,"Planning programs are loose, high-level, declarative representations of the behavior of agents acting in a domain and following a path of goals to achieve. Such programs are specified through transition systems that can include cycles and decisions to make at certain points. We investigate a new effective approach for solving the problem of realizing a planning program, i.e., informally, for finding and combining a collection of plans that guarantee the planning program executability. We focus on deterministic domains and propose a general algorithm that solves the problem exploiting a planning technique handling goal constraints and preferences. A preliminary experimental analysis indicates that our approach dramatically outperforms the existing method based on formal verification and synthesis techniques."
http://videolectures.net/icaps2011_thayer_inadmissible/,"Suboptimal search algorithms offer shorter solving times by sacrificing guaranteed solution optimality. While optimal search algorithms like A* and IDA* require admissible heuristics, suboptimal search algorithms need not constrain their guidance in this way. Previous work has explored using off-line training to transform admissible heuristics into more effective inadmissible ones. In this paper we demonstrate that this transformation can be performed on-line, during search. In addition to not requiring training instances and extensive precomputation, an on-line approach allows the learned heuristic to be tailored to a specific problem instance. We evaluate our techniques in four different benchmark domains using both greedy best-first search and bounded suboptimal search. We find that heuristics learned on-line result in both faster search and better solutions while relying only on information readily available in any best-first search."
http://videolectures.net/icaps2011_fern_ensemble/,"Monte-Carlo planning algorithms, such as UCT, select actions at each decision epoch by intelligently expanding a single search tree given the available time and then selecting the best root action. Recent work has provided evidence that it can be advantageous to instead construct an ensemble of search trees and to make a decision according to a weighted vote. However, these prior investigations have only considered the application domains of Go and Solitaire and were limited in the scope of ensemble configurations considered. In this paper, we conduct a more exhaustive empirical study of ensemble Monte-Carlo planning using the UCT algorithm in a set of six additional domains. In particular, we evaluate the advantages of a broad set of ensemble configurations in terms of space and time efficiency in both parallel and single core models. Our results demonstrate that ensembles are an effective way to improve performance per unit time given a parallel time model and performance per unit space in a single-core model. However, contrary to prior isolated observations, we did not find significant evidence that ensembles improve performance per unit time in a single-core model."
http://videolectures.net/icaps2011_albore_effective/,"Conformant planning can be formulated as a path-finding problem in belief space where the two main challenges are the heuristics to guide the search, and the representation and update of beliefs. In the translation-based approach recently introduced by Palacios and Geffner, the two aspects are handled together by translating conformant problems into classical ones that are solved with classical planners. While competitive with state-of-the-art methods, the translation-based approach runs however into three difficulties. First, complete translations are expensive for problems with high width; second, incomplete translations can generate infinite heuristic values for problems that are solvable; and third, aspects that are specific to the conformant setting, such as the cardinality of beliefs, are not accounted for. In this work, we build on the translation-based approach but not for solving conformant problems with a classical planner but for deriving heuristics and computing beliefs in the context of a standard belief-space planner. For this, a novel translation KSi is introduced that is always complete, but which is sound for problems with width bounded by i. A new conformant planner, called T1, builds then on this translation for i=1, extending the heuristic that results with a second heuristic obtained from invariant ""one of expressions"". A number of experiments is performed to compare T1 with state-of-the-art conformant planners."
http://videolectures.net/icaps2011_lipovetzky_designed/,"We define a probe to be a single action sequence computed greedily from a given state that either terminates in the goal or fails. We show that by designing these probes carefully using a number of existing and new polynomial techniques such as helpful actions, landmarks, commitments, and consistent subgoals, a single probe from the initial state solves by itself 683 out of 980 problems from previous IPCs, a number that compares well with the 627 problems solved by FF in EHC mode, with similar times and plan lengths. We also show that by launching one probe from each expanded state in a standard greedy best first search informed by the additive heuristic, the number of problems solved jumps to 900 (92%), as opposed to FF that solves 827 problems (84%),and LAMA that solves 879 (89%). The success of probes suggests that many domains can be solved easily once a suitable serialization of the landmarks is found, an observation that may open new connections between recent work in planning and more classical work concerning goal serialization and problem decomposition in planning and search."
http://videolectures.net/icaps2011_machado_polytime/,"We present a software tool that is able to automatically translate an NP problem into a STRIPS problem such that the former problem has a solution if the latter has one, a solution for the latter can be transformed into a solution for the former, and all this can be done efficiently. Moreover, the tool is built such that it only produces problems that belong to a fragment of STRIPS that is solvable in non-deterministic polynomial time, a fact that guarantees that the whole approach is not an overkill. This tool has interesting applications. For example, with the advancement of planning technology, it can be used as an off-the-shelf method to solve general NP problems with the help of planners and to automatically generate benchmark problems of known complexity in a systematic and controlled manner. Another interesting contribution is related to the area of Knowledge Engineering in which one of the goals is to devise automatic methods for using the available planning technology to solve real-life problems."
http://videolectures.net/icaps2011_bonet_landmarks/,A collection of landmarks is complete if the cost of a minimum-cost hitting set equals h+ and there is a minimum-cost hitting set that is an optimal relaxed plan. We present an algorithm for generating a complete collection of landmarks and we show that this algorithm can be extended into effective polytime heuristics for optimal and satisficing planning. The new admissible heuristics are compared with current state-of-the-art heuristics for optimal planning on benchmark problems from the IPC.
http://videolectures.net/icaps2011_keller_polynomial/,"Most predominant approaches in probabilistic planning utilize techniques from the more thoroughly investigated field of classical planning by determinizing the problem at hand. In this paper, we present a method to map probabilistic operators to an equivalent set of probabilistic operators in a novel normal form, requiring polynomial time and space. From this, we directly derive a determinization which can be used for, e.g., replanning strategies incorporating a classical planning system. Unlike previously described all outcome determinizations, the number of deterministic operators is not exponentially but polynomially bounded in the number of parallel probabilistic effects, enabling the use of more sophisticated determinization-based techniques in the future."
http://videolectures.net/icaps2011_mansley_markov/,"In this paper, we present a new algorithm that integrates recent advances in solving continuous bandit problems with sample-based rollout methods for planning in Markov Decision Processes (MDPs). Our algorithm, Hierarchical Optimistic Optimization applied to Trees (HOOT) addresses planning in continuous-action MDPs. Empirical results are given that show that the performance of our algorithm meets or exceeds that of a similar discrete action planner by eliminating the problem of manual discretization of the action space."
http://videolectures.net/icaps2011_bryce_domains/,"Engineering complete planning domain descriptions is often very costly because of human error or lack of domain knowledge. Learning complete domain descriptions is also very challenging because many features are irrelevant to achieving the goals and data may be scarce. We present a planner and agent that respectively plan and act in incomplete domains by i) synthesizing plans to avoid execution failure due to ignorance of the domain model, and ii) passively learning about the domain model during execution to improve later re-planning attempts. Our planner DeFault is the first to reason about a domain’s incompleteness to avoid potential plan failure. DeFault computes failure explanations for each action and state in the plan and counts the number of interpretations of the incomplete domain where failure will occur. We show that DeFault performs best by counting prime implicants (failure diagnoses) rather than propositional models. Our agent Goalie learns about the preconditions and effects of incompletely-specified actions while monitoring its state and, in conjunction with DeFault plan failure explanations, can diagnose past and future action failures. We show that by reasoning about incompleteness (as opposed to ignoring it) Goalie fails and re-plans less and executes fewer actions."
http://videolectures.net/icaps2011_to_contingent/,"This paper introduces a highly competitive contingent planner, that uses the novel idea of encoding belief states as disjunctive normal form formulae (To et al. 2009), for the search for solutions in the belief state space. In (To et al. 2009), a complete transition function for computing successor belief states in the presence of incomplete information has been defined. This work extends the function to handle non-deterministic and sensing actions in the AND/OR forward search paradigm for contingent planning solutions. The function allows one, under reasonable assumptions, to compute successor belief states efficiently, i.e., in polynomial time. The paper also presents a novel variant of an AND/OR search algorithm, called PrAO (Pruning AND/OR search), which allows the planner to significantly prune the search space; furthermore, by the time a solution is found, the remaining search graph is also the solution tree for the contingent planing problem. The strength of these techniques is confirmed by the empirical results obtained from a large set of benchmarks available in the literature."
http://videolectures.net/icaps2011_gefen_seed/,"This paper defines and studies a new, interesting, and challenging benchmark problem that originates in systems biology. The minimal seed-set problem is defined as follows: given a description of the metabolic reactions of an organism, characterize the minimal set of nutrients with which it could synthesize all nutrients it is capable of synthesizing. Current methods used in systems biology yield only approximate solutions. And although it is natural to cast it as a planning problem, current optimal planners are unable to solve it, while non-optimal planners return plans that are very far from optimal. As a planning problem, it is inherently delete-free, has many zero-cost actions, all propositions are landmarks, and many legal permutations of the plan exist. We show how a simple uninformed search algorithm that exploits inherent independence between sub-goals can solve it optimally by reducing the branching factor drastically."
http://videolectures.net/icaps2011_tipaldi_robots/,"As robots enter environments that they share with people, human-aware planning and interaction become key tasks to be addressed. For doing so, robots need to reason about the places and times when and where humans are engaged into which activity and plan their actions accordingly. In this paper, we first address this issue by learning a non homogenous spatial Poisson process whose rate function encodes the occurrence probability of human activities in space and time. We then present two planning problems for human robot interaction in social environments. The first one is the maximum encounter probability planning problem, where a robot aims to find the path along which the probability of encountering a person is maximized. We are interested in two versions of this problem, with deadlines or with a certainty quota. The second one is the minimum interference coverage problem, where a robot performs a coverage task in a socially compatible way by reducing the hindrance or annoyance caused to people. An example is a noisy vacuum robot that has to cover the whole apartment having learned that at lunch time the kitchen is a bad place to clean. Formally, the problems are time dependent variants of known planning problems: MDPs and price collecting TSP for the first problem and the asymmetric TSP for the second. The challenge is that the cost functions of the arcs and nodes vary with time, and that execution time is more important that optimality, given the real-time constraints in robotic systems. We present experimental results using variants of known planners and formulate the problems as benchmarks to the community."
http://videolectures.net/icaps2011_koehler_applications/,"Disclaimer: VideoLectures.NET emphasizes that this talk was not recorded in its full duration but due to its content value was published with the permission of the author. In this talk, I will review some of my personal experiences made when applying AI planning to industrial problems and review one of the most successful planning applications in the area of elevator control.  I also take a quick look at current planners and briefly discuss how they could be made more ready for practical applications, however, this requires efforts in areas that are appreciated by real users, but not so much rewarded by the academic value system."
