0,1
http://videolectures.net/sikdd2019_sunar_preferences_of_users/,"In education we can find different open educational resource (OER) providers that are serving resources in different modalities, formats and languages. These providers can be the actual resource creators or re-distributors that redirect the user to the actual provider. In recent work, we developed a recommendation engine which provides content-based recommendations from multiple resource providers, enabling the users to navigate between the providers and their resources. In this paper, we investigate the users’ choice on the recommended items focusing on the cross-site user learning activities. The results show that the users tend to stay on the same website and not choose the first item in the recommendation list."
http://videolectures.net/sikdd2019_torkar_stock_price_forecasting/,"This paper aims at assessing the performance of the transfer learning task consisting of training set of classiffiers on high frequency financial news data for 74 publicly traded companies, with domain speciffic labels. This source of data is provided by the Jozef Stefan Institute and is used exclusively for the purposes of this research. The trained classiffiers are then used to attribute labels to an unlabelled source of high frequency aggregated news, Event-Registry. The aim is for the relabelled data to be used in the generation of exogenous features for use in time series forecasting of the companies' prices. It is found that using a fine-tuned BERT [1] model yields the most semantically coherent labels, and the features generated from the newly labelled data prove to yield the highest accuracy forecasts on held out price data."
http://videolectures.net/sikdd2019_bizjak_latent_distance_graphs/,"Network analysis is one of the main topics in modern data analysis, since it enables us to reason about systems by studying their inner relations, for example we can study a network by analyzing its edges. However, in many cases it is impossible to detect or measure the network directly, due to noisy data for example. We present a method for dealing with such systems, more concretely we present a probabilistic model called latent distance network, which we use to model news data from EventRegistry. In the end of the article we also present experimental results on predictions of latent distance model with methods of machine learning"
http://videolectures.net/sikdd2019_kenda_feature_selection/,Applying machine learning to Big Data can be a cumbersome task which requires a lot of computational power and memory. In this paper we present a feature selection technique for land-cover classiffication in earth observation scenario. The technique extends the state-of-the-art feature extractors by pruning the dimensionality of the required feature space and can achieve almost optimal results with 10-fold reduction of the number of features. The approach utilizes a genetic algorithm for generation of optimal feature vector candidates and multi-objective optimization techniques for candidate selection.
http://videolectures.net/sikdd2019_cerin_satellite_images/,"The weather is one of the main factors for events that happen on the surface of the earth. Surprisingly, no effort was made to use weather features together with satellite images for land cover classiffication. In the paper, we use temperature data along with satellite images to improve the accuracy of the classiffication and to get classiffication as early in the year as possible. Every year has different conditions, so the temperature can be used as an objective criterion at what time to do classiffication."
http://videolectures.net/sikdd2019_costa_analysis_of_influenza/,"The need for appropriate, robust and efficient epidemic intelligence tools is increasing in this age of a connected society. Global health initiatives, such as Influenzanet, potentially have a central role in the future of Public Health. This paper presents the contributions to the Influenzanet initiative, describing a new monitoring system for local hubs and their data sources, based on Elasticsearch. It is often the case that the exploration of internally generated data is prioritised by national public health institutions, and therefore cannot be addressed in the global Influenzanet platform. This platform can be used by health professionals without programming expertise to encourage and enhance their independence from busy in-house IT departments and further contribute to the effectiveness of their own research. The most meaningful data visualization modules can then be considered for integration into the full Influenzanet platform that will serve the complete network, thus collaborating at a global level. With this approach we also show the importance that an active hub in carrying out its own investigations towards its own priorities. In that regard and as an example, we also describe new results on the application of state-of-the-art approaches to a local data set, using the Portuguese ILI seasons between 2005 and 2013. This study is based on the application of the Streamstory approach. It aims to show the potential of this versatile approach in: (i) identifying data-driven ILI seasons; (ii) relating the ILI incidence to the dimensions of weather data; and (iii) comparing the incidence throughout four different ILI definitions."
http://videolectures.net/sikdd2019_mattiev_class_association/,"Associative classification (AC) is a data mining approach that combines classification and association rule mining to build classification models (classifiers). Experimental results show that in average the CBA-based approaches could achieve higher accuracy than some of the traditional classification methods. In this paper, we focus on associative classification, where class association rules are generated and analyzed to build a simple, compact, understandable and relatively accurate classifier. Furthermore, we discuss how overall coverage and average rule coverage of such classifiers affect their classification accuracy. We compare our method that uses constrained exhaustive search with some “classical” classification rule learning algorithm that uses greedy heuristic search on accuracy in some “real-life” datasets. We have performed experiments on 11 datasets from UCI Machine Learning Database Repository. Experimental evaluation shows that with decreasing overall coverage our proposed method tends to get slightly worse classification accuracy than the “classical” classification rule learning algorithms. Otherwise, the accuracy is similar or on some datasets even better than Naive Bayes and C4.5. On the other hand, the average rule coverage of our proposed method seems to have no effect on classification accuracy."
http://videolectures.net/sikdd2019_massri_legal_domain_documents/,"In text mining document enrichment processes are used to improve information retrieval. Document enrichment helps us extract metadata from the text which can then be used in document classiffication. This paper presents the legal domain document enrichment process and analysis of the enriched data. The process of enriching the documents with multiple layers of annotations is described. The focus is on legal domain documents data set, but the proposed procedure can be generalized to any type of documents."
http://videolectures.net/sikdd2019_mladenic_grobelnik_next_big_thing/,"This paper presents an approach to predicting the future development of scientific research based on scientific publications from the past two centuries. We have applied machine learning methods on the Microsoft Academic Graph dataset of scientific publications. Our experimental results show that the best performance is obtained for a noticeable increase of the topic frequency in the last 5 years compared to the previous 10 years. In this case, our model achieves precision of 74.3, recall of 71.7 and F1 of 73.0. Some topics that our model identified as promising are: proton proton collisions, higgs boson, quark, hadron, mobile augmented reality, variable quantum, molecular dynamics simulations, hadronic final states, search for dark matter"
http://videolectures.net/sikdd2019_urbancic_environmental_legal_documents/,"Finding similar documents in a big document corpus based on context has many practical applications especially in the legal sector. In this paper, our focus is on the documents related to environmental law which have been collected in a database of approximately 300k documents. We analyzed the performance of different representation models (called document embeddings) on our database and found that evaluating the results is difficult, due to the size of the database. The approaches presented can be applicable for other text datasets."
http://videolectures.net/sikdd2019_kavsek_mobility_data/,"Today we are used to being interconnected via our smartphones and having our phone location tracked by different apps. ICT technology enables real-time monitoring and processing the user location data from GPS coordinates of a phone. Based on observing the user mobility, Artificial Intelligence methods can be used to improve transportation, proactively provide mobility recommendations and acquire knowledge using the user context. This paper describes the application of machine learning algorithms on user mobility data to identify and understand potentially interesting events. The data for this research was collected from a sample of users consenting to be monitored through our in-house developed smart phone app. A pilot study that includes 227 users that were tracked over a period of 7 years yields fairly positive evaluation results in terms of predictive accuracy of identified events but succeeds in identifying exclusively “well-known” events related to users going to or coming from the office and/or lunch. This shows that machine learning methods can be a suitable choice for identifying events in mobility data but there is still room for improvement."
http://videolectures.net/sikdd2019_costa_health_news_bias/,"The impact of health-related news in today’s society is increasing as is the awareness of the globalization of the worlds’ habits and threats, and the impact on the continuous pursuit of a better quality of life. The risk of news media bias and the consequences it might have in the population is of great concern for public health, as are the available resources to identify the bias and further explore the news stories. In this paper we discuss several aspects, angles and perspectives on news media bias in the health domain, with a particular focus on digital epidemiology. We also present decision support tools developed to support decision makers in these explorations in the context of the MIDAS project, leveraging Big Data analytics to support decision making in public health. The presented resources provide health professionals with a global perspective on the worldwide news coverage of monitored health topics (such as, e.g., infectious diseases, mental health or childhood obesity), together with a workflow of tools allowing them to explore potential bias. Moreover, we discuss the specific challenges of news bias in the health domain, analyzing some typical examples, and using the Event Registry technology to further explore them. The exploration potential of the latter, in the health domain, is enhanced with the integration of an automated classifier based on MeSH Headings that allows researchers to explore the news using a similar workflow to that of exploring biomedical research in PubMed."
http://videolectures.net/sikdd2019_rozanec_multiple_sources/,"Demand is the amount of certain product required by buyers at a point in time. Demand forecasting tries to predict future demand based on available information. It is considered a key component of each manufacturing company since improvements on it translate directly to resources planning, stocks and overall operations. In the context of Industry 4.0, industry digitalization provides an everincreasing number of data sources which can be consumed to gain visibility over all operations and used to optimize different processes within it. This also opens new possibilities into the field of demand forecasting, where multiple data sources can be integrated to get timely data for accurate forecasts. We describe an efficient approach for demand forecasting for discrete components B2B industry. The proposed approach provides as good or better forecasts as logisticians for most months in six months period and achieves savings considering all test months period"
http://videolectures.net/sikdd2019_kojanec_seizure_detection/,"One third of all epileptic patients is resistant to medical treatment. The construction of machines, that would detect an imminent epileptic attack based on EEG signals, represents an efficient alternative, that would help to increase their quality of life. In this article we described the implementation of an automatic detection method, based on the signal of different frequency sub-bands, using topographic maps and deep learning techniques. We constructed an ensemble of five convolutional neural networks, to classify samples of each sub-band and chose the final decision by a majority voting. The ensemble obtained 99.20% accuracy, 96.48% sensitivity and 99.27% specificity when detecting seizures of one patient. Moreover, when the networks were trained with samples taken randomly from the inter-ictal intervals, we identified on 18 of 21 seizures some false positive classifications close to the seizure onset, thus anticipating the detection of the seizure. Such misclassifications did not occur when training was performed with samples taken within five minutes of the seizure onset."
http://videolectures.net/sikdd2018_novak_natural_language_processing/,"In education we can find millions of video, audio and text educational materials in different formats and languages. This variety and multimodality can impose difficulty on both students and teachers since it is hard to find the right materials that match their learning preferences. This paper presents an approach for retrieving and recommending items of different modalities. The main focus is on the retrieving and preprocessing pipeline, while the recommendation engine is based on the k-nearest neighbor method. We focus on educational materials, which can be text, audio or video, but the proposed procedure can be generalized on any type of multi-modal data."
http://videolectures.net/sikdd2018_novalija_relation_tracker/,"In this paper, we present Relation Tracker, a tool that tracks main entities [people and organizations] within each topic through time. The main types of relations between the entities are detected and observed in time. The tool provides multiple ways of visualizing this information with different scales and durations. The tool uses events data from Event Registry as a source of information, with the aim of getting holistic insights about the searched topic"
http://videolectures.net/sikdd2018_novalija_labour_market_domain/,"In this paper, we present a proposal for developing smart labour market statistics based on streams of enriched textual data and illustrate its application on job vacancies from European countries. We define smart statistics scenarios including demand analysis scenario, skills ontology development scenario and skills ontology evolution scenario. We identify stakeholders – consumers for smart statistics and define the initial set of smart labour market statistical indicators"
http://videolectures.net/sikdd2018_urbancic_transporation_mode_detection/,"This paper addresses transportation mode detection for a mobile phone user using machine learning and based on mobile phone sensor data. We describe our approach to data collection, preprocessing and feature extraction. We evaluate our approach using random forest classification with focus on feature selection. We show that with feature selection we can significantly improve classification scores."
http://videolectures.net/sikdd2018_jovanoski_anomaly_detection_approach/,"inter-connected, spanning over a range of computing devices. As software systems are being split into modules and services, coupled with an increasing parallelization, detecting and managing anomalies in such environments is hard. In practice, certain localized areas and subsystems provide strong monitoring support, but cross-system error-correlation, root-cause analysis and prediction are an elusive target. We propose a general approach to what we call Full-spectrum anomaly detection - an architecture that is able to detect local anomalies on data from various sources as well as creating high-level alerts utilizing background knowledge, historical data and forecast models. The methodology can be implemented either completely or partially."
http://videolectures.net/sikdd2018_costa_support_public_health/,"Today’s society is data rich and information driven, with access to numerous data sources available that have the potential to provide new insights into areas such as disease prevention, personalised medicine and data driven policy decisions. This paper describes and demonstrates the use of text mining tools developed to support public health institutions to complement their data with other accessible open data sources, optimize analysis and gain insight when examining policy. In particular we focus on the exploration of MEDLINE, the biggest structured open dataset of biomedical knowledge. In MEDLINE we utilize its terminology for indexing and cataloguing biomedical information – MeSH – to maximize the efficacy of the dataset."
http://videolectures.net/sikdd2018_koprivec_crop_classification/,"Efficient and accurate classification of land cover and land usage can be utilized in many different ways: ranging from natural resource management, agriculture support to legal and economic processes support. In this article, we present an implementation of land cover classiffication using the PerceptiveSentinel platform. Apart from using base 13 bands, only minor feature engineering was performed and different classiffication methods were explored. We report an F1 and accuracy score (80-90%) in range of state of the art when using pixel-wise classiffication and even comparable to time series based land cover  classiffication."
http://videolectures.net/sikdd2018_kostovska_machine_learning_datasets/,"With the exponential growth of data in all areas of our lives, there is an increasing need of developing new approaches for effective data management. Namely, in the field of Data Mining (DM) and Knowledge Discovery in Databases (KDD), scientists often invest a lot of time and resources for collec- ting data that has already been acquired. In that context, by publishing open and FAIR (Findable, Accessible, Interoperable, Reusable) data, researchers could reuse data that was previously collected, preprocessed and stored. Motivated by this, we conducted extensive review on current approaches, data repositories and semantic technologies used for annotation, storage and querying of datasets for the domain of machine learning (ML) and data mining. Finally, we identify the limitations of the existing repositories of datasets and propose a design of a semantic data repository that adheres to FAIR principles for data management and stewardship."
http://videolectures.net/sikdd2018_tolovski_data_mining_models/,"Semantic annotation provides machine readable structure to the stored data. We can use this structure to perform semantic querying, based on explicitly and implicitly derived information. In this paper, we focus on the approaches in semantic annotation, storage and querying in the context of data mining models and experiments. Having semantically annotated data mining models and experiments with terms from domain ontologies and vocabularies will enable researchers to verify, reproduce, and reuse the produced artefacts and with that improve the current research. Here, we first provide an overview of state-of-the-art approaches in the area of semantic web, data mining domain ontologies and vocabularies, experiment databases, representation of data mining models and experiments, and annotation frameworks. Next, we critically discuss the presented state-of-the-art. Further-more, we sketch our proposal for an ontology-based system for semantic annotation, storage, and querying of data mining models and experiments. Finally, we conclude the paper with a summary and future work."
http://videolectures.net/sikdd2018_kresz_prediction_model/,"We present a new model for probabilistic forecasting using graph-based rating method. We provide a \forward-looking"" type graph-based approach and apply it to predict football game outcomes by simply using the historical game results data of the investigated competition. The assumption of our model is that the rating of the teams after a game day correctly reflects the actual relative performance of them. We consider that the smaller the changing of the rating vector {contains the ratings of each team { after a certain outcome in an upcoming single game, the higher the probability of that outcome. Performing experiments on European foot- ball championships data, we can observe that the model performs well in general and outperforms some of the advanced versions of the widely-used Bradley-Terry model in many cases in terms of predictive accuracy. Although the application we present here is special, we note that our method can be applied to forecast general graph processes."
http://videolectures.net/sikdd2017_brank_wikipedia_concepts/,We describe an efficient approach for annotating a document with relevant concepts from the Wikipedia. A pagerank-based method is used to identify a coherent set of relevant concepts considering the input document as a whole. The proposed approach is suitable for parallel processing and can support any language for which a sufficiently large Wikipedia is available.
http://videolectures.net/sikdd2017_mladenic_news_events/,"In this work we investigate how news events can be used to predict the financial markets. Namely we built a time series model that includes features obtained from the news and investigated whether the changes in volume of traded shares can be predicted more accurately with this information. The time series model that was built is of an ARMA-GARCH type, because we wanted to account for any clustering of the volatility that is normal for the financial markets. The models were evaluated with the Akaike and Bayesian Information Criterion, while also being compared to the base-line model that did not include any features from the news. Overall our results show that there is an improvement in the model when the information from the news is used and hence show a promising avenue for future research work."
http://videolectures.net/sikdd2017_pita_costa_public_health/,"Real-time global media monitoring is nowadays an essential resource to public health. Multilingual capabilities can enrich this potential allowing a worldwide overview based on online news sources, blog posts or social media. In this paper we propose research topics related with the exploration text mining tools used to provide real-time global media monitoring in the context of health. We aim to understand how media can contribute to a better overview of health related and well being matters. With it we shall also identify open research questions that motivate further technological development to better fit the needs, interests and workflow of public health professionals."
http://videolectures.net/sikdd2017_kladnik_topic_profiles/,"Audience segmentation is often applied on Web portals to gain insights into the audience, support targeted marketing and in general provide on-line recommendations to the users. We propose an approach to audience segmentation that is based on using machine learning on topic profiles of the visited content. Our preliminary experiments on a small sample of log-data show that the proposed approach is promising and the proposed combination of features capturing short term and long-term user interest gives better results than using only the short-term interests of the user."
http://videolectures.net/sikdd2017_herga_detail_records/,"Data collected from mobile phones can be used to uncover underlying social network dynamics and individual's behavioral patterns. Based on a Call Details Records dataset, we build a weighted, directed network and analyze it's properties. In addition to node-level network measures we extract an extensive consumption and mobility-based feature set. We show that extracted network and consumption features can be used to model individual's risk profile."
http://videolectures.net/sikdd2017_novak_skill_demand/,"Todays job market demand from the job seekers to continuously learn new skills. When applying for a job position one must have the required skill set. If the applicant is missing a skill it can be learned by attending a course. Finding the appropriate courses can be tedious but necessary work to be up-to-date with the job market demand. In this paper, we present a dashboard which connects the job market skill demand with the courses that give the required skill knowledge. We developed a pipeline for continuous crawling of job postings and courses which feeds the dashboard with the appropriate data. The dashboard allows searching by keywords and returns relevant job postings, courses and basic statistics relevant to the given search query."
http://videolectures.net/sikdd2017_skraba_execution_anomalies/,"Anomaly detection (a.k.a. outlier detection) is the identification of events that do not conform to an expected pattern in a dataset. When applied to monitoring modern, complex IT systems, it keeps track of a plethora of incoming data streams. This paper provides an approach that uses the lowest and most unstructured source of data related to an IT system - the raw system log files. Several versions and parametrizations of basic building blocks will be presented to show how different types of anomalies can be extracted from the data. Several experiments on synthetic as well as real-world data show effectiveness of the algorithm. Special care is taken to keep the model and the resulting alerts interpretable - since detecting an error without a meaningful explanation about its details is of limited use to end user (the results need to be actionable)."
http://videolectures.net/sikdd2017_kenda_higgs_boson/,"Real-time classification of events in high energy physics is essential to deal with huge amounts of data, produced by proton-proton collisions in ATLAS detector at Large Hadron Collider in CERN. With this work we have implemented a triggering mechanism method for saving relevant data, based on machine learning. In comparison with the state of the art machine learning methods (gradient boosting and deep neural networks) shortcomings of Support Vector Machines (SVM) have been compensated with extensive feature engineering. Method has been evaluated with special metrics (average median significance) suggested by the domain experts. Our method achieves significantly higher precision and 8% lower average median significance than the current state of the art method used at ATLAS detector (XGBoost)."
http://videolectures.net/sikdd2017_pita_costa_data_analysis/,"Networks are important representations in computer science to communicate structural aspects of a given system of interacting components. The evolution of a network has several topological properties that can provide us information on the network itself. In this paper, we present a methodology to compare the the topological characteristics of the evolution of a network, encoded into a (persistence) diagram that tracks the lifetimes of those features. This will enable us to classify the evolution of networks based on the distance between the diagrams that represent such network evolution. In that, we also consider complex vectors that bring a complementary perspective to the distance-based classification that is closer to the computational methods, aims to enhance the computational efficiency of those comparisons, and that is by itself a source of open research questions."
http://videolectures.net/sikdd2017_kocbek_mortality_prediction/,"Numerous severity assessment scores for estimation of in-hospital mortality in Intensive Care Unit (ICU) have been developed over the last 40 years. In this study, we predicted 1-month mortality in chronic kidney disease (CKD) patients using the open Medical Information Mart for Intensive Care III (MIMIC III) database. Additionally, we observed the improvement in predictive performance and interpretability of the baseline model used in ICUs to a more complex model using simple features such as unigrams or bigrams, as well as advanced features extracted from textual nursing notes. For the latter, MetaMap extraction tool was used to extract medical concepts based on the Unified Medical Language System (UMLS) terminology. We used a logistic regression based classifier, built using Simplified Acute Physiology Score II (SAPS II), age and gender, as a baseline model. The baseline model was then compared to regularized logistic regression based classifier built using simple and more complex additional features. The Area Under the ROC Curve (AUC) results for the baseline predictive performance improved from of 0.761 to 0.782 when frequency of unigrams and bigrams were used to build the model. In a similar scenario, where unigram and bigram frequency was replaced with Term Frequency–Inverse Document Frequency (TF-IDF) based feature values, AUC further increased to 0.786. This paper represents an opportunity in extracting new knowledge in the form of unigrams, bigrams or concepts extracted from textual notes accompanied by regression coefficient values that can be interpreted as relations between the features and the outcome. The combination of both can provide added value in decision support systems in ICU departments, where data is collected in electronic medical records (EMRs) in real-time."
http://videolectures.net/sikdd2016_choloniewski_slovene_media/,"We present results of a study on usage of text similarity measures based on co-occurrence of words and phrases to classify a relation between a pair of news articles (i.e. no relation, both based on a common source, one based on the other). For each Slovenian article written in Slovene and published online on 27th June 2016, we found the most similar release from the Slovenian Press Agency (STA) database to obtain a list of candidate article-source pairs. Four experts from STA were asked to score the pairs, and their annotations were used to train classifiers and evaluate their accuracy."
http://videolectures.net/sikdd2016_kladnik_website_visit_logs/,"This paper provides three use-cases of combining website visit logs with user segment data, website content and stock volume data. The use-cases provide concrete examples showcasing how to derive insights into behavior of users on the website. We also present how to efficiently derive required data using MapReduce technique, and implement the use-cases using QMiner data analytics platform."
http://videolectures.net/sikdd2016_novak_videoLectures/,"This paper presents learning analytics tools for visual and statistical analysis of data from a portal of video lectures. While learning analytics methods traditionally deal with measurement, collection and analysis of data about learners with an aim of improving the learning process, our solutions are targeted at viewers of VideoLectures.NET. The novel VideoLectures Learning Analytics Dashboard and Lecture Landscape tools allow observing, searching and analyzing viewer behavior and, at the same time, efficiently present the information from the portal to the viewers."
http://videolectures.net/sikdd2016_pita_costa_aquaculture/,"The specific challenges in aquaculture today reveal needs and problems that must be addressed appropriately and in sync with the most recent optimization methods. It is now the time to bring the techniques of aquaculture to a new level of development and understanding. In that, one must consider the state of the art methods of statistics and data mining that permit a deeper insight into the aquaculture reality through the collected datasets, either from daily data or from sampling to sampling data. This must also be tuned to the expert knowledge of the fish farmers, their procedures and technology in use today. In this paper we review the state of the art of data analytics methodology in aquaculture, the data available deriving from the procedures characteristic to this business, and propose mathematical models that permit a deeper insight on the data. We also address the data unknowns and strategies developed that will contribute to the success of the business, leading to discover valuable information from the data that can be made usable, relevant and actionable."
http://videolectures.net/sikdd2016_senozetnik_clustering_methods/,"Tracking a person, an animal, or a vehicle generates a vast amount of spatio-temporal data, that has to be processed and analyzed differently from ordinary data generally used in knowledge discovery. This paper presents existing spatiotemporal clustering algorithms, suitable for such data and compares their running time, noise sensitivity, quality of results and the ability to discover clusters according to nonspatial, spatial and temporal values of the objects."
http://videolectures.net/sikdd2016_urbancic_accelerometer_readings/,"This paper describes a method for automatic transportation mode detection based on smartphone sensors. Our approach is designed to work in real-time as it only requires 5s of sensor readings for the detection. Because we used accelerometer instead of GPS signal it uses less battery power and is therefore more user and phone-friendly. For the mode detection we use multiple support vector machine models which enable us distinguishing between multiple modes (bus, train, car). Before the classification, raw measurements are preprocessed in order to cancel out the constant acceleration that is caused by the force of gravity. The results of the paper are promising and are based on the collected training data from approximately 20 hours of driving on trains and public buses in Ljubljana."
http://videolectures.net/sikdd2016_herga_modeling_probability/,"Creditors carry the risk of their clients not meeting their debt obligations. In the literature, these events are often referred to as default events. These can be modeled for each company through a probability of default (PD). Measures can be taken to limit the default risk: in this paper we focused on credit limit. Firstly, we predict PD of a company using a logistic regression model, based on publicly available financial data. Secondly, we effectively find an optimal portfolio under risk aversion constraints and show how variation of inputs affects the results."
http://videolectures.net/sikdd2016_fuart_innovation_funding_programmes/,"This paper gives an introduction to the European Programme for Internet Innovation and the needs for advanced analytical techniques in assessment of the socio-economic impact of funded projects. A technical overview and architecture of developed IT tools follows. Broadly, two set of tools were explored. (1) An on-line assessment environment that provides programme managers and companies with feedback about their potential socio-economic impact. For this set of tools the emphasis is on visualisation techniques, therefore a detailed rationale and scientific background for those is provided with usage examples. (2) Statistical modules for identification of funding approaches that, potentially, provide best results (”best practices”) have been developed and applied to available data. Through one use-case we have shown that the proposed IT system is useful in measuring the impact of innovation funding programmes, detecting good management practices and giving support to funded projects. The whole system has been published on a public repository with an open source license, giving opportunity to re-use, customize and integrate the reporting system into other impact assessment environments."
http://videolectures.net/sikdd2015_belyaeva_pursuit_news/,"The paper addresses a problem of pursuit of journalistic news values, more specifically frequency, threshold and proximity through various text mining methods is presented. We illustrate how text mining can assists journalistic work by finding ideological, often orthodox news values of different international publishers across the world news that contribute to ubiquitous news bias. Our experiments on selected publishers and on news about Apple’s launch of new iPhone 6 and Apple Watch confirm that journalists still follow some of the well known journalistic values."
http://videolectures.net/sikdd2015_gubiani_mining_literature/,"In this paper we demonstrate how literature mining can support experts in biomedicine on their way towards new discoveries. This is very important in complex, not yet sufficiently understood domains, where connections between different sub-specialities and fields of expertise have to be connected to fully understand the phenomena involved. As a case study, we present our preliminary literature mining work in the domain of ageing. The results confirm very recent discoveries about connections between diet and degenerative diseases, and indicate some concrete directions for further research needed to reveal the connections between microbiota and Alzheimer disease."
http://videolectures.net/sikdd2015_eftimov_bakery_products/,"In this paper, we present the analytical results of the ingredients matching in bakery products. We collected recipes from a free recipes web site and the main goal was to find association rules between the recipes’ ingredients. For this purpose we applied an Apriori algorithm and various visualization techniques to represent the discovered association rules. The paper covers: data extraction, data preprocessing, association rules and visualization of the results during this work"
http://videolectures.net/sikdd2015_zajec_ngram_collection/,"This paper presents an efficient indexing technique suitable for indexing large n-gram collections with an emphasis on full wildcard query support and speed efficiency. Further we used this technique in building the n-gram search engine, on top of Google’s Web 1T 5-gram collection, whose advantages are interactive querying and fast result retrieval with tradeoff on higher memory consumption."
http://videolectures.net/sikdd2015_rei_event_detection/,"We present two methods for event detection in Twitter using an event knowledge base. The knowledge base used contains world events reported in the media that we identify as multi-lingual clusters of mainstream news stories. Given this fact, we reduce the problem of event detection to matching tweets to mainstream news stories. The first method consists of using URLs to mainstream news sites present in tweets and in the knowledge base. We use this method to build a supervised corpus of tweets and then create and evaluate a supervised classifier as our second method. Experimental evaluation on real-world data shows that the proposed methods perfom well on our dataset"
http://videolectures.net/sikdd2015_panov_ontodm_ontology/,"This paper presents the first steps towards integrating concepts from the field of network analysis into the OntoDM ontology of data mining concepts. We have performed an extensive analysis of different subfieds of network analysis to provide a broad overview of the variety of tasks and algorithms that are encountered in the field. The main part of this work was to categorize the tasks and algorithms into a hierarchy that is consistent with the structure of OntoDM and which can systematically cover as many aspects of network analysis as possible. This work is a first step in the direction of OntoDM becoming an ontology that systematically describes not only data mining, but also network analysis. We believe that this work will encourage other researchers working in the filed to provide additional insight and further improve the integration of this field into OntoDM."
http://videolectures.net/sikdd2015_stopar_multiscale_methodology/,"This paper presents a novel, multi-scale, framework, for the simultaneous analysis of multiple data streams, called StreamStory. The framework models the data streams as a hierarchical Markovian model by automatically learning states and transitios, and aggregating them into a hierarchy of Markov chains. This approach aims to compensate the gap between lowlevel streaming observations and high-level output/alerts which provide a value for higher levels of streaming data analysis, like inference and prediction, and provides ground for qualitative interpretation of the data."
http://videolectures.net/sikdd2015_valmarska_inverted_heuristics/,"In rule learning, rules are typically induced in two phases, rule refinement and rule selection. It was recently argued that the usage of two separate heuristics for each phase—in particular using the so-called inverted heuristic in the refinement phase—produces longer rules with comparable classifi- cation accuracy. In this paper we test the utility of inverted heuristics in the context of subgroup discovery. For this purpose we developed a DoubleBeam subgroup discovery algorithm that allows for combining various heuristics for rule refinement and selection. The algorithm was experimentally evaluated on 20 UCI datasets using 10-fold double-loop cross validation. The experimental results suggest that a variant of the DoubleBeam algorithm using a specific combination of refinement and selection heuristics generates longer rules without compromising rule quality. However, the DoubleBeam algorithm using inverted heuristics does not outperform the standard CN2-SD and SD algorithms."
http://videolectures.net/sikdd2015_kenda_energy_scenarios/,"Fusing heterogeneous multivariate data in stream mining scenarios is a demanding task. Successful fusion requires a wellthought approach. We propose the use of a stream processing engine (SPE) that enables implementation of all the needed methods and ensures almost real-time responsiveness of the system. In the paper we propose an infrastructure that is able to receive data from various heterogeneous sources (static properties, weather data and forecasts, other forecasts, and primarily sensor data). In the implementation of the proposed infrastructure we address issues related to the heterogeneous nature of the data, like different frequency, different update interval, and different nature of the data. The pipeline was used to prepare stream prediction models for five different energy-related use cases, which include public buildings, a thermal plant production, university campus buildings, and EPEX energy spot market prices alongside the total traded energy."
http://videolectures.net/sikdd2015_moraru_forecasting_sales/,"Smart cities are an important topic in today’s research problems, with high impact in many domains from economy to transportation, health and living style. The problem addressed in this paper is that of sales forecasting for a specific category of products. We present the results of three regression algorithms, applies on real live data, for predicting the cumulative hourly sales of petrol. The prediction is made for three short term intervals, of 1, 4, and 8 hours into the future. A study has also been conducted in order to identify the amount of historical data required for optimal results."
http://videolectures.net/sikdd2015_costa_topological_data/,"Influenzanet is a system to monitor the activity of influenza-like-illness [ILI] with the aid of internet volunteers. Topological data analysis [TDA] examines the structure of data and contributes to the development of medicine, studying properties of a continuous space by the analysis of a discrete sample of it. Using TDA we analyze the topology of Influenzanet data identifying noise and distinguishing higher dimension features. This is done both in terms of the overall structure of a disease as well as its evolution. It provides a way to test agreement at a global scale arising from standard local models. We also compare this qualitative method to other quantitative methods such as Fourier analysis or dynamical time warping [DTW]."
http://videolectures.net/sikdd2015_breskvar_alzheimer_patients/,"This paper presents experiments with Predictive Clustering Trees that uncover several subpopulations of the Alzheimer’s disease patients. Our experiments are based on previous research that identified the everyday cognition as one of the most important testing domains in the clinical diagnostic process for the Alzheimer’s disease. We are investigating which biological features have a role in the progression of the disease by observing behavioral response of the patients and their study partners. Our dataset includes 342 male and 317 female patients from the ADNI database that are described with 243 clinical and biological attributes. The resulting clusters, described in terms of biological features, show behavioral and gender specific differences between clusters of patients with progressed disease. These findings suggest a possibility that the Alzheimer’s disease is manifested through different biological pathways."
http://videolectures.net/sikdd2014_hruschka_labeling_facts/,"Never-Ending Language Learner (NELL)1  is a computer  system that runs 24/7, forever, learning to read the web.  extract (read) more facts from the web, and integrate these  into its growing knowledge base of beliefs; and ii) learn to  read better than yesterday, enabling it to go back to the text  it read yesterday, and today extract more facts, more  accurately. This system has been running 24 hours/day for  over four years now. The result so far is a collection of 70  million interconnected beliefs (e.g., servedWith(coffee,  applePie), isA(applePie, bakedGood)), that NELL is  considering at different levels of confidence, along  with hundreds of thousands of learned phrasings,  morphological features, and web page structures that NELL  uses to extract beliefs from the web2 ."
http://videolectures.net/sikdd2014_rei_large_scale/,"We present a semi-automatic data exploration and  organization tool. The system integrates machine learning  and text mining algorithms into an simple user interface and  a Client/Server architecture. The main features of the  systems include unsupervised and supervised methods for  concept suggestion, visualization and ability to make both  data and methods available to other applications as a  service."
http://videolectures.net/sikdd2014_novalija_media_mining/,"This paper presents an approach to social media mining  based on a pipeline that implements observing, enriching,  storing, modeling and presentation techniques. While social  media mining solutions have been used for information  extraction and sentiment identification about certain topics,  applying social media for modeling and nowcasting is a  promising new research direction. A novel tool  TwitterObservatory that allows observing, searching,  analyzing and presenting social media is introduced as a  part of the research. Illustrative examples of using the  proposed pipeline show how the TwitterObservatory  implementing the pipeline can support the user in  interaction with the social media data."
http://videolectures.net/sikdd2014_dimitrovski_data_visualization/,"Twitter is the leading micro-blogging and social network  service and is attracting an enormous amount of  attention in recent years. Users on Twitter generate an  abundance of information every day, establishing  Twitter as the focal point for analyzing and visualizing  social media data.  In this paper, we present a web tool for visualizing  Twitter data, TweetViz. TweetViz offers several different  kinds of visualizations that can pertain to a Twitter user  or any keyword or hashtag entered through the interface.  TweetViz also includes a so called Streamgraph  visualization that represents topic distribution in a set of tweets. The topic distributions are created using LDA  (Latent Dirichlet Allocation)."
http://videolectures.net/sikdd2014_dobsa_textual_documents/,"In this research is presented algorithm for classification  of textual documents which are represented in the space  of reduced dimension in respect to original bag of words  representation. Algorithm is carried out in two steps: in  the first step classification is conducted for documents  represented in original bag of words representation,  while in the second step classification is conducted for  documents represented in the space of reduced  dimension. Reduction of dimensionality is obtained also  in two steps: in the first step documents are represented  by usage of latent semantic indexing, while in the second  step this representation is projected on the space of  membership matrix defining a membership of  documents in classes. Evaluation of algorithm is  conducted on Reuters21578 collection of documents."
http://videolectures.net/sikdd2014_brank_stream_documents/,"We present an efficient approach for clustering a massive stream  of textual documents, with particular emphasis on parallelization  by the means of multithreaded processing. The underlying  clustering algorithm is adaptable to changes in the stream and  includes the ability to split and merge clusters, as well as to  discard old data."
http://videolectures.net/sikdd2014_zdravkova_multiword_expressions/,"One of the crucial challenges of statistical machine  translation is the lexical consistency of manually translated  words and multiword expressions (MWEs) with multiple  occurrences in the source language. In this paper, we present  the degree of translation inconsistency and we introduce the  index of translation completeness of fixed MWEs. The  research was based on the recently developed system that  intends to extract the entire candidate MWEs from Orwell’s  1984 parallel corpora and to predict their translations  between English, Macedonian, and Slovene."
http://videolectures.net/sikdd2014_kazic_event_detection/,"When dealing with large amounts of heterogeneous traffic  data streams, how a Complex Event Processing (CEP)  system, which can efficiently process and predict complex  events in traffic, is set up is a crucial matter. In this paper,  several issues and methods related to finding different rules  that can be used to develop such a system are presented.  Statistical methods to detect complex events from traffic  data are first described. Two types of techniques are used to  research relations between complex events: descriptive and  predictive data mining. First, association rules are used to  analyze data and express regularities in data. Second,  decision trees and decision rules algorithms are used for the  prediction of complex events.  All the algorithms were tested with regards to how different  social events affect the traffic system near the Stozice  stadium in Ljubljana, Slovenia. The results show that  methods described in this paper are feasible and can be  used for developing an advanced traveler information  system."
http://videolectures.net/sikdd2014_kovacic_government_transparency/,"This paper presents usage of Supervizor, an online  application that provides information on financial  transactions of the public sector bodies. Supervizor  contains by now 50 mio. transactions from both  government and local agencies to government  contractors from 2003 to 2014 and matches such  transactions to company records from the Business  Register including director lists and corporate  leadership. The application, which has been designed  and developed by the Commission for the Prevention of  Corruption, won the UN Public Service Award in 2013,  an important recognition of excellence in public service.  The data on transactions from Supervizor are also  provided in machine readable form."
http://videolectures.net/sikdd2014_hajdinjak_supply_data/,"This paper presents a data mining approach for demand  and supply data arising from economic statistics. It is  based on demand and supply functions with different  types of price elasticities, which can be used to identify  interesting patterns and data dependencies. Constant,  directly proportional and linear price elasticities are  considered."
http://videolectures.net/sikdd2013_novalija_fashion_collection/,"This paper presents an approach to developing a fashion domain ontology based on inputs from fashion experts and natural language processing (NLP) methods. While many of software solutions for fashion industry are concentrated on the design, manufacturing and trading applications, semantic technologies are just starting to interact with fashion domain. Domain ontologies allow capturing, sharing, analyzing and reusing the important information from the defined field."
http://videolectures.net/sikdd2013_herga_support_prototype/,"The purpose of this paper is to present the approach to knowledge acquisition and computer reasoning support in a call center environment. The common problem in such environments (especially in technical call centers) is that the call operators are usually just the interface to the experts inside the company. They often lack the detailed technical knowledge in the field of study, especially when they are newcomers who just started with their job. For this reason we developed the expert system (ES) that is able to obtain needed expertise from technical staff and it is able to assist less technically versed operators to provide feedback to customers and acquire the knowledge needed to fix the particular customer problem. The prototype implementation of the ES was built for the national roadside assistance call center which is focused on car fault diagnosis."
http://videolectures.net/sikdd2013_starc_relation_arguments/,"In this paper, we propose an iterative semi-automatic approach for linking textual arguments of relations to their semantic form using rules. Textual arguments are completely decomposed – every word is considered. They are composed back into semantic form using functions, which bring additional semantic information. The process starts with an initial set of seed rules, which can be obtained automatically. In each iteration, the user constructs new rules using the recommendations, which are calculated based on the frequency statistics of unlinked textual arguments. Our approach was tested on extraction of roles that people have in organizations. The results show that only 31 human crafted rules are needed to link more than 3400 additional arguments. We also show that combining rules have positive effects. The number of linked arguments grows super-linearly with respect to the number of patterns."
http://videolectures.net/sikdd2013_dali_news_search/,"In this paper we study the problem of guessing what search query the user intends to type into a search engine based on the first few characters of the query, also known as prefix based query auto-completion. We train and evaluate two personalized auto-completion models on search logs from an online news portal. The personalization comes from using demographic and location information specific to the user. Our experiments show that we can guess the query the user intended to type and rank it among the top three suggestions over 75 % of the time. Moreover, the methods described can decrease the number of keystrokes by about 40%, thus saving the user a lot of typing."
http://videolectures.net/sikdd2013_speh_dirichlet_allocation/,"We review three algorithms for parameter estimation of the Latent Dirichlet Allocation model: batch variational Bayesian inference, online variational Bayesian inference and inference using collapsed Gibbs sampling. We experimentally compare their time complexity and performance. We find that the online variational Bayesian inference converges faster than the other two inference techniques, with comparable quality of the results."
http://videolectures.net/sikdd2013_moraru_tweets_events/,"Social events happening in a city can influence and affect a large number of the citizens, directly or indirectly involved. Having a metric to measure the popularity of such events can help in estimating the resources needed for handling them, improving facilities such as public transportation or traffic estimations. This paper reports on the problem of association of Tweet messages to social events in order to discover the popularity of an event. We propose and evaluate a method that computes an association coefficient for an event-tweet pair and discuss the results obtained."
http://videolectures.net/sikdd2013_kenda_kalman_filter/,"This paper presents a methodology for data cleaning of sensor data using the Kalman filter. The Kalman filter is an on-line algorithm and as such is ideal for usage on the sensor data streams. The Kalman filter learns parameters of a user-specified underlying model which models the phenomena the sensor is measuring. Usage of the Kalman filter is proposed to predict the expected values of the measuring process in the near future and to detect the anomalies in the data stream. Furthermore the Kalman filter prediction can be used to replace missing or invalid values in the data stream. Algorithm only requires sensor measurements as an input, which makes it ideal to be placed as near to the resource tier in the N-tier architecture as possible."
http://videolectures.net/sikdd2013_kenda_asset_management/,"This paper presents the conceptual architecture of the system for optimization of maintenance of assets that are equipped with adequate sensors. Beside the conceptual architecture we also present our implementation in the telecommunications use case, where we developed a system that helps optimizing technician response time and reduces effort needed for resolving problems with maintaining the mobile telephony base stations."
http://videolectures.net/sikdd2013_kazic_activity_recognition/,"The focus of this work is to explore the possibilities of recognizing three common user activities (sitting, walking and running) with accelerometer data from smartphones. Among five common machine learning algorithms, Naïve Bayes classifier proved to be the best choice. Classification accuracy of more than 90% was achieved when phone is carried in a pocket. It is shown that this method is appropriate and that the phone’s orientation information is not needed. Finally, the classification of one day-long data set is presented."
http://videolectures.net/sikdd2013_trampus_bercic_diversified_news/,"With the ever-increasing ease and speed of opinion exchange, the internet often displays the echo chamber effect. This is exacerbated by a free market: search engines and other data aggregators are monetarily incentivized to primarily show the most popular opinions. We propose a data aggregation, processing and retrieval system to combat this phenomenon in the domain of web news. We developed two applications (web, iOS) that allow users to explore news articles along several uncommon imensions, diversifying them and discovering new aspects of a story. The iOS application works in real time, making for a novel alternative to classic news reader apps. Our user study shows a need for such diversity-aware approaches and judges our solution to be directly useful."
http://videolectures.net/sikdd2013_niaksu_multirelational_settings/,The paper deals with a distance based multi-relational clustering application in a real data case study. A novel method for a dissimilarity matrix calculation in multi-relational settings has been proposed and implemented in R language. The proposed method has been tested by analyzing public actions related to data mining subject and indexed in the medical index database MedLine. Clustering based on partitioning around methods was used for the semi-automated identification of the most popular topics among the MedLine publications. The algorithm implements greedy approach and is suitable for small data sets with a limited number of 1:n relational joins.
http://videolectures.net/sikdd2011_hsuan_privacy/,"This talk will examine the current debate about how KDD research should be legally regulated, and what it means if privacy rights fail to be protected . . . and what it could mean if they are."
http://videolectures.net/sikdd2011_canhasi_multidocument/,"Multi-document summarization is a process of automatic creation of a compressed version of the given collection of documents. Recently, the graph-based models and ranking algorithms have been extensively researched by the extractive document summarization community. While most work to date focuses on sentence-level relations in this paper we present graph model that emphasizes not only sentence level relations but also the influence of under sentence level relations (e.g. a part of sentence similarity). By using the proven cognitive psychology model (the Event-Indexing model) and semantic role parsing for generating the frame graph, we establish the bases for distinguishing the sentence level relations. Based on this model, we developed an iterative frame and sentence ranking algorithm, based on the existing well known PageRank algorithm. Experiments are conducted on the DUC 2004 data sets and the ROUGE (Recall-Oriented Understudy for Gisting Evaluation) evaluation results demonstrate the advantages of the proposed approach."
http://videolectures.net/sikdd2011_mladenic_assertions/,"We present an early version of a method for open-domain semantic assertion extraction from natural language texts. To combat the shortage of training data for the task, a two-stage pipeline is employed: we first perform semantic role labeling, then map the resulting frames onto predicate-form, ontology-aligned statements. We chose FrameNet and Cyc as the frame database and the ontology, respectively."
http://videolectures.net/sikdd2011_karlovcec_community/,"Using advanced analysis techniques new useful insight into data can be achieved. This paper addresses a problem of gaining insights in the data on scientific collaboration on a National level, where data can be seen as a graph with researchers and research content. Two existing visualization techniques were applied on data about scientific community in Slovenia: collaboration diagram and competence map. Collaboration diagram gives a clear overview of collaborations for a selected researcher, while competence map shows semantically grouped research content the researcher has worked on."
http://videolectures.net/sikdd2011_skrbec_archives/,"This paper proposes a pipeline for searching and browsing through newspaper archives. It uses a combination of algorithms for extracting information from text and tools for visualizing different text structures capable of handling large amount of articles that are normally collected in archives. The proposed pipeline is implemented as a web application, illustrative results show appropriateness of the proposed pipeline for searching and browsing news archives."
http://videolectures.net/sikdd2011_zdravkova_ghostwriter/,"Ghostwriting became students’ most popular way to avoid writing of boring essays, or the best way to easily earn by writing on behalf of another student. This paper presents several markers indicating a presence of potential ghostwriters. Proposed methodology suggests various inspection techniques, which do not prove anything in isolation. Whenever they are jointly implemented, they successfully cluster the essays, suggesting plausible absence, potential and almost certain presence of one or few ghostwriters. After the initial clustering, all the papers go through subtle linguistic check. In our sample, later approach discovered some unexpected phrases which confirmed the presence of the same ghostwriters not only in the current, but also in the previous generations."
http://videolectures.net/sikdd2011_tomasev_hubness/,"Hubness is a phenomenon present in many highdimensional data sets. It is related to the skewness in the distribution of k-occurrences, i.e. occurrences of data points in k-neighbor sets of other data points. Several hubnessaware methods that focus on exploiting this phenomenon have recently been proposed. In this paper, we examine the potential impact of weighting the k-occurrences, by taking into account the distance between the respective data points, on hubness-aware nearest-neighbor methods, more specifically hw-kNN, h-FNN and HIKNN. We show that such distance-based weighting can be both advantageous and detrimental and that it influences different methods in different ways."
http://videolectures.net/sikdd2011_gjorgjioski_classification/,"Multi-label classification has received significant attention in the research community over the past few years: this has resulted in the development of a variety of multi-label classification methods. These methods either transform the multi-label dataset to several simpler datasets or adapt the learning algorithm so it can handle the multiple labels. In this paper, we consider the latter approach. Namely, we use predictive clustering trees to perform multi-label classification. Furthermore, we perform an experimental comparison of four distance measures used to select the splits in the nodes of the trees. The experimental evaluation was conducted on 6 benchmark datasets using 6 different evaluation measures. The results show that, averaged overall, the Euclidean distance and the Hamming loss yield the best predictive performance."
http://videolectures.net/sikdd2011_brank_hierarchical/,"One of the ways of approaching a multiclass classification problem is to transform it into several two-class (binary) classification problems. An ensemble of binary classifiers is trained for these tasks and their predictions are combined using a voting method into predictions for the original multiclass problem. Each of the new binary problems uses some of the original classes as positive training data, some classes as negative training data and the remaining classes (if any) are not used at all. The relationship between classes (of the original problem) and binary classifiers can be concisely represented by a matrix called the coding matrix. In this paper we explore some of the statistical properties of the space of coding matrix based classifiers in the context of a small hierarchical multiclass learning problem."
http://videolectures.net/sikdd2011_chudan_olap/,"The paper presents a comparison of possibilities and proposal for complementary use of OLAP and the rich variant of association rule mining based on the GUHA method. The rationale is to determine the point when it is useful for the analyst to proceed from OLAP to descriptive data mining, as well as the point of return from data mining results to OLAP in order to see them in a broader view."
http://videolectures.net/sikdd2011_kosir_multilingual/,"An online advertising network connects web content providers and advertisers enabling the providers to monetize their content and the advertisers to reach online consumers. In this paper we study the workings of a successful state-of-the-art online advertising network with branch offices all over the world. The framework is designed to support different targeting strategies and advertising in multiple languages. We describe the implementation of contextual and behavioral targeting, and also discuss different methods to evaluating these strategies. Statistics show that by employing contextual targeting instead of random targeting we can achieve significantly higher CTR values."
http://videolectures.net/sikdd2011_tomasev_oceanographic/,"In this paper we examine how the high dimensionality of oceanographic sensor data impacts the potential use of nearest-neighbor machine learning methods. We focus on one particular consequence of the curse of dimensionality – hubness. We examine the hubness of oceanographic data and show how it can be used to visualize and detect both prototypical sensors/locations, as well as ambiguous and potentially erroneous ones. We proceed to define an easy classification problem on the data, showing that the recently developed hubness-aware classification methods may help to overcome some of the hubness-related issues in sensor data."
http://videolectures.net/sikdd2011_leban_duplicates/,"Bug tracking systems (BTS) are systems that allow users of some software to report to developers bugs they encountered while using it. Common problem of BTS are duplicated reports of the same bug. Since identifying bug duplicates is a time consuming task we show in this paper an approach to automatically identifying duplicates using text-mining methods. We demonstrate the usability of our method on KDE Bugzilla BTS which contains 249,083 bug reports of which 47,093 are duplicates."
http://videolectures.net/sikdd2011_pracner_wikimage/,"This paper presents work towards the creation of free and redistributable datasets of correlated images and text. Collections of free images and related text were extracted from Wikipedia with our new tool WIKImage. An additional tool – WIKImage browser – was introduced to visualize the resulting dataset, and was expanded into a manual labeling tool. The paper presents a starting dataset of 1007 images labeled with any combination of 14 tags.  The images were processed into a number of scale invariant (SIFT) and color histogram features, and the captions were transformed into a bag-of-words (BOW) representation. Experiments were then performed with the aim of classifying data with respect to each of the labels on dataset variants with just the image information, just the textual data, and both, in order to estimate the difficulty of the dataset in the context of different feature spaces. Results indicate improvements in precision, recall and the F-measure when using the combined representation with support vector machines as well as the k-nearest neighbor classifier with the cosine similarity measure."
http://videolectures.net/sikdd2011_farajikhah_madanchi_spectral/,"In this study, the principal component analysis (PCA) technique and its nonlinear version (NLPCA) are employed for the compression and reconstruction of spectral data. The reflectance spectra of 1269 matt Munsell color chips are used as original dataset in 400 to 700 nm with 10 nm intervals. The hidden patterns of spectral data are determined by employing the classical PCA as well as its nonlinear version. Different numbers of feature vectors are used in both methods and the results compared by using the root mean square error (RMS), the goodness fit coefficients (GFC) as well as the color difference values under D65 illuminant and 1964 standard observer. Results show the priority of NLPCA over the PCA in low-dimensional spaces i.e. up to 4 basic functions, while different results are observed in higher-dimensional spaces."
http://videolectures.net/sikdd08_dali_tes/,"In this paper we present a machine learning approach to extract subject-predicate-object triplets from English sentences.  SVM is used to train a model on human annotated triplets, and the features are computed from three parsers."
http://videolectures.net/sikdd08_rusu_sgdt/,"Information nowadays has become more and more accessible, so much as to give birth to an information overload issue. Yet important decisions have to be made, depending on the available information. As it is impossible to read all the relevant content that helps one stay informed, a possible solution would be condensing data and obtaining the kernel of a text by automatically summarizing it. We present an approach to analyzing text and retrieving valuable information in the form of a semantic graph based on subject-verb-object triplets extracted from sentences. Once triplets have been generated, we apply several techniques in order to obtain the semantic graph of the document: coreference and anaphora resolution of named entities and semantic normalization of triplets. Finally, we describe the automatic document summarization process starting from the semantic representation of the text. The experimental evaluation carried out step by step on several Reuters newswire articles shows a comparable performance of the proposed approach with other existing methodologies. For the assessment of the document summaries we utilize an automatic summarization evaluation package, so as to show a ranking of various summarizers."
http://videolectures.net/sikdd08_rupnik_ssa/,"This paper is an overview of a recent approach for solving linear support vector machines (SVMs), the PEGASOS algorithm. The algorithm is based on a technique called the stochastic subgradient descent and employs it for solving the optimization problem posed by the soft margin SVM - a very popular classifier.  We briefly introduce the SVM problem and one of the widely used solvers, SVM light, then describe the PEGASOS algorithm and present some experiments. We conclude that the algorithm efficiently discovers suboptimal solutions to large scale problems within a matter of seconds."
http://videolectures.net/sikdd08_aleksovski_fpa/,"Distance-based algorithms for both clustering and prediction are popular within the machine learning community. These algorithms typically deal with attributevalue (single-table) data. The distance functions used are typically hard-coded. We are concerned here with generic distance-based learning algorithms that work on arbitrary types of structured data. In our approach, distance functions are not hard-coded, but are rather first-class citizens that can be stored, retrieved and manipulated. In particular, we can assemble, on-the-fly, distance functions for complex structured data types from pre-existing components. To implement the proposed approach, we use the strongly typed functional language Haskell. Haskell allows us to explicitly manipulate distance functions. We have produced a SW library/application with structured data types and distance functions and used it to evaluate the potential of Haskell as a basis for future work in the field of distancebased machine learning."
http://videolectures.net/sikdd08_rupnik_imt/,"Part-of-speech (PoS) or, better, morphosyntactic tagging is the process of assigning morphosyntactic categories to words in a text, an important pre-processing step for most human language technology applications. PoS-tagging of Slovene texts is a challenging task since the size of the tagset is over one thousand tags (as opposed to English, where the size is typically around sixty) and the state-of-the-art tagging accuracy is still below levels desired. The paper describes an experiment aimed at improving tagging accuracy for Slovene, by combining the outputs of two taggers – a proprietary rule-based tagger developed by the Amebis HLT company, and TnT, a tri-gram HMM tagger, trained on a handannotated corpus of Slovene. The two taggers have comparable accuracy, but there are many cases where, if the predictions of the two taggers differ, one of the two does assign the correct tag. We investigate training a classifier on top of the outputs of both taggers that predicts which of the two taggers is correct. We experiment with selecting different classification algorithms and constructing different feature sets for training and show that some cases yield a meta-tagger with a significant increase in accuracy compared to that of either tagger in isolation."
http://videolectures.net/sikdd08_novalija_eo/,"Ontologies are commonly used for annotating textual data mainly based on human language technologies [1]. This research focuses on manual extensions of ontologies to support the annotation of business news. Experiments were conducted on a well known Cyc ontology and using Cyc annotator on two business news datasets. We show that the proposed extensions of ontology results in annotation with better coverage of terms that are relevant for the business domain.  The results of identifying financial terms in business news using the original Cyc ontology show the average precision of 56% and recall of 41% in case of Reuters news and the average precision of 69% and the recall of 57% in case of Yahoo financial news. Using the proposed extension results with increased performance, the average precision of 82% and average recall of 73% for Yahoo financial news and average precision of 84% and average recall of 63% for Reuters news."
http://videolectures.net/sikdd08_fortuna_smtm/,"The variety of access and transport technologies available in modern computer networks pose significant challenges related to compatibility and quality of service (QoS) related issues. Applications and services can have many different and unique requirements towards the transportation services (TSs) they use to interconnect. Traditionally, applications are required to specify their QoS requirements in the language which the TSs understand. This results in reformulation of intuitive parameters (i.e. desired video resolution) to parameters understood by the TSs (i.e. required bandwidth). paper presents techniques for (a) automatic matchmaking of application requirements to the offers by TSs providers and (b) automatic translation of application requirements into the TSs QoS requirements. To this end semantic technologies, namely OpenCyc, are used for ontological modeling, translation and matchmaking. We present relevant examples on how semantic technologies can be used in the context of communication networks."
http://videolectures.net/sikdd08_dimitrovski_hami/,"In this paper, we describe an approach for the automatic medical annotation task of the 2008 CLEF cross-language image retrieval campaign (ImageCLEF). The data comprise 12076 fully annotated images according to the IRMA code. This work is focused on the process of feature extraction from images and hierarchical multi-label classification. To extract features from the images we used a technique called: local distribution of edges.  With this techniques each image was described with 80 variables. The goal of the classification task was to classify an image according to the IRMA code. The IRMA code is organized hierarchically. Hence, as classifer we selected an extension of the predictive clustering trees (PCTs) that is able to handle this type of data.  Further more, we constructed ensembles (Bagging and Random Forests) that use PCTs as base classifiers."
http://videolectures.net/sikdd08_bullas_si/,"Over three hundred four-second / 40hz time series datasets (from simulated emergency braking manoeuvres at English fatal accident sites and field trials) were classified using key characteristics of the braking sequences extracted for each event. These characteristics were then tested for significant difference between road surface types and braking system types. One key marker, average deceleration, was also compared against existing benchmark ‘typical’ values for acceptable performance as found in the literature."
http://videolectures.net/sikdd08_popovic_cpm/,"The paper presents model based on fuzzy methods for churn prediction in retail banking. The study was done on the real, anonymised data of 5000 clients of a retail bank. Real data are great strength of the study, as a lot of studies often use old, irrelevant or artificial data. Canonical discriminant analysis was applied to reveal variables that provide maximal separation between clusters of churners and non-churners. Combination of standard deviation, canonical discriminant analysis and k-means clustering results were used for outliers detection. Due to the fuzzy nature of practical customer relationship management problems it was expected, and shown, that fuzzy methods performed better than the classical ones. According to the results of the preliminary data exploration and fuzzy clustering with different values of the input parameters for fuzzy c-means algorithm, the best parameter combination was chosen and applied to training data set. Four different prediction models, called prediction engines, have been developed. The definitions of clients in the fuzzy transitional conditions and the distance of k instances fuzzy sums were introduced. The prediction engine using these sums performed best in churn prediction, applied to both balanced and non-balanced test sets."
