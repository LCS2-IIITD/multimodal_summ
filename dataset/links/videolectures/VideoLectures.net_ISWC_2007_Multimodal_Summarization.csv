Video_Presentation,Abstracts
http://videolectures.net/iswc07_kahle_uahk/,"The goal of universal access to our cultural heritage is within our grasp. With current digital technology we can build comprehensive collections, and with digital networks we can make these available to students and scholars all over the world. The current challenge is establishing the roles, rights, and responsibilities of our libraries and archives in providing public access to this information. With these roles defined, our institutions will help fulfill this epic opportunity of our digital age."
http://videolectures.net/iswc07_pell_nlpsw/,"The Semantic Web promises to revolutionize access to information by adding machine-readable semantic information to content which is normally interpretable only by people. In addition, it will also revolutionize access to services by adding semantic information to create machine-readable service descriptions. This ambitious vision has been slow to take off because of a chicken and egg problem. Markup is required before people will build applications, applications are required before it is worth the hard work of doing markup. Natural language processing (NLP) has advanced to the point where it can break the impasse and open up the possibilities of the Semantic Web. First, NLP systems can now automatically create annotations from unstructured text. This provides the data that semantic web applications require. Second, NLP systems are themselves consumers of semantic web information and thus provide economic motivation for people to create and maintain such information. For example, a new generation of natural language search systems, as illustrated by Powerset, can take advantage of semantic web markup and ontologies to augment their interpretation of underlying textual content. They can also expose semantic web services directly in response to natural language queries."
http://videolectures.net/iswc07_welty_hiwr/,"For the past several years I have warned people not to ask me to predict the future, because my predictions are usually wrong. Undaunted by failure, in this talk I will try to predict the future of the semantic web based on a very personal view of its history, the history of the internet, web, semantic web, and AI, and the mistakes I've made predicting where and how they would be valuable."
http://videolectures.net/iswc07_southampton_upp/,"Governments often hold very rich data and whilst much of this information is published and available for re-use by others, it is often trapped by poor data structures, locked up in legacy data formats or in fragmented databases. One of the great benefits that Semantic Web (SW) technology offers is facilitating the large scale integration and sharing of distributed data sources. At the heart of information policy in the UK, the Office of Public Sector Information (OPSI) is the part of the UK government charged with enabling the greater re-use of public sector information. This paper describes the actions, findings, and lessons learnt from a pilot study, involving several parts of government and the public sector. The aim was to show to government how they can adopt SW technology for the dissemination, sharing and use of its data."
http://videolectures.net/iswc07_gangemi_cswl/,"This talk introduces a framework to add a semantic web layer to  legacy organizational information, and describes its application to the use case  provided by the Italian National Research Council (CNR) intraweb. Building on  a traditional web-based view of information from different legacy databases, we  have performed a semantic porting of data into a knowledge base, dependent on  an OWL domain ontology. We have enriched the knowledge base by means of  text mining techniques, in order to discover on-topic relations. Several reasoning  techniques have been applied, in order to infer relevant implicit relationships.  Finally, the ontology and the knowledge base have been deployed on a semantic  wiki by means of theWikiFactory tool, which allows users to browse the ontology  and the knowledge base, to introduce new relations, to revise wrong assertions in  a collaborative way, and to perform semantic queries. In our experiments, we have  been able to easily implement several functionalities, such as expert finding, by  simply formulating ad-hoc queries from either an ontology editor or the semantic  wiki interface. The result is an intelligent and collaborative front end, which allow  users to add information, fill gaps, or revise existing information on a semantic  basis, while keeping the knowledge base automatically updated."
http://videolectures.net/iswc07_health_rsw/,"Semantic Web conferences such as ESWC and ISWC offer  prime opportunities to test and showcase semantic technologies. Conference  metadata about people, papers and talks is diverse in nature and  neither too small to be uninteresting or too big to be unmanageable.  Many metadata-related challenges that may arise in the Semantic Web  at large are also present here. Metadata must be generated from sources  which are often unstructured and hard to process, and may originate from  many different players, therefore suitable workflows must be established.  Moreover, the generated metadata must use appropriate formats and vocabularies,  and be served in a way that is consistent with the principles  of linked data. This paper reports on the metadata efforts from ESWC  and ISWC, identifies specific issues and barriers encountered during the  projects, and discusses how these were approached. Recommendations  are made as to how these may be addressed in the future, and we discuss  how these solutions may generalize to metadata production for the  Semantic Web at large."
http://videolectures.net/iswc07_zhou_akqss/,"Semantic search promises to provide more accurate result  than present-day keyword search. However, progress with semantic search  has been delayed due to the complexity of its query languages. In this paper,  we explore a novel approach of adapting keywords to querying the  semantic web: the approach automatically translates keyword queries  into formal logic queries so that end users can use familiar keywords to  perform semantic search. A prototype system named ‘SPARK’ has been  implemented in light of this approach. Given a keyword query, SPARK  outputs a ranked list of SPARQL queries as the translation result. The  translation in SPARK consists of three major steps: term mapping, query  graph construction and query ranking. Specifically, a probabilistic query  ranking model is proposed to select the most likely SPARQL query. In  the experiment, SPARK achieved an encouraging translation result."
http://videolectures.net/iswc07_harth_frs/,"We present the architecture of an end-to-end semantic search  engine that uses a graph data model to enable interactive query answering  over structured and interlinked data collected from many disparate  sources on the Web. In particular, we study distributed indexing methods  for graph-structured data and parallel query evaluation methods on  a cluster of computers. We evaluate the system on a dataset with 430  million statements collected from the Web, and provide scale-up experiments  on 7 billion synthetically generated statements."
http://videolectures.net/iswc07_xie_tbd/,"Data warehouse is now widely used in business analysis and decision making processes. To adapt the rapidly changing business environment, we develop a tool to make data warehouses more business-friendly by using Semantic Web technologies. The main idea is to make business semantics explicit by uniformly representing the business metadata (i.e. conceptual enterprise data model and multidimensional model) with an extended OWL language. Then a mapping from the business metadata to the schema of the data warehouse is built. When an analysis request is raised, a customized data mart with data populated from the data warehouse can be automatically generated with the help of this built-in knowledge. This tool, called Enterprise Information Asset Workbench (EIAW), is deployed at the Taikang Life Insurance Company, one of the top five insurance companies of China. User feedback shows that OWL provides an excellent basis for the representation of business semantics in data warehouse, but many necessary extensions are also needed in the real application. The user also deemed this tool very helpful because of its flexibility and speeding up data mart deployment in face of business changes."
http://videolectures.net/iswc07_wang_por/,"Extracting semantic relations is of great importance for the creation of the Semantic Web content. It is of great benefit to semi-automatically extract relations from the free text of Wikipedia using the structured content readily available in it. Pattern matching methods that employ information redundancy cannot work well since there is not much redundancy information in Wikipedia, compared to the Web. Multi-class classification methods are not reasonable since no classification of relation types is available in Wikipedia. In this paper, we propose PORE (Positive-Only Relation Extraction), for relation extraction from Wikipedia text. The core algorithm B-POL extends a state-of-the-art positive-only learning algorithm using bootstrapping, strong negative identification, and transductive inference to work with fewer positive training examples. We conducted experiments on several relations with different amount of training data. The experimental results show that B-POL can work effectively given only a small amount of positive training examples and it significantly outperforms the original positive learning approaches and a multi-class SVM. Furthermore, although PORE is applied in the context of Wikipedia, the core algorithm B-POL is a general approach for Ontology Population and can be adapted to other domains."
http://videolectures.net/iswc07_tkk_fhi/,"This talk shows how semantic web techniques can be applied to solving problems of distributed content creation, discovery, linking, aggregation, and reuse in health information portals, both from end-users’ and content publishers’ viewpoints. As a case study, the national semantic health portal HEALTHFINLAND is presented. It provides citizens with intelligent searching and browsing services to reliable and up-to-date health information created by various health organizations in Finland. The system is based on a shared semantic metadata schema, ontologies, and ontology services. The content includes metadata about thousands of web documents such as web pages, articles, reports, campaign information, news, services, and other information related to health."
http://videolectures.net/iswc07_huynh_dmn/,"As more and more reusable structured data appears on the Web, casual users will want to take into their own hands the task of mashing up data rather than wait for mash-up sites to be built that address exactly their individually  unique needs. In this paper, we present Potluck, a Web user interface that lets casual users—  those without programming skills and data modeling expertise—mash up data themselves.  Potluck is novel in its use of drag and drop for merging fields, its integration and extension of the faceted browsing paradigm for focusing on subsets of data to align, and its application of simultaneous editing for cleaning up data syntactically. Potluck also lets the user construct rich visualizations of data in-place as the user aligns and cleans up the data. This iterative process of integrating  the data while constructing useful visualizations is desirable when the user is unfamiliar with the data at the beginning—a common case—and wishes to get immediate value out of the data without having to spend the overhead of completely and perfectly integrating the data first.  A user study on Potluck indicated that it was usable and learnable, and elicited  excitement from programmers who, even with their programming skills, previously had great difficulties performing data integration."
http://videolectures.net/iswc07_yamauchi_swh/,"For the development of Semantic Web technology, researchers and  developers in the Semantic Web community need to focus on the areas in which  human reasoning is particularly difficult. Two studies in this paper demonstrate  that people are predisposed to use class-inclusion labels for inductive judgments.  This tendency appears to stem from a general characteristic of human  reasoning – using heuristics to solve problems. The inference engines and interface  designs that incorporate human reasoning need to integrate this general  characteristic underlying human induction."
http://videolectures.net/iswc07_oren_wold/,"Developers of SemanticWeb applications face a challenge with  respect to the decentralised publication model: where to nd statements  about encountered resources. The \linked data"" approach, which man-  dates that resource URIs should be de-referenced and yield metadata  about the resource, helps but is only a partial solution.We present Sindice,  a lookup index over resources crawled on the Semantic Web. Our index al-  lows applications to automatically retrieve sources with information about  a given resource. In addition we allow resource retrieval through inverse-  functional properties, oer full-text search and index SPARQL endpoints."
http://videolectures.net/iswc07_motta_esw/,"The increased availability of online knowledge has led to the design of several algorithms that solve a variety of tasks by harvesting the Semantic Web, i.e., by dynamically selecting and exploring a multitude of online ontologies. Our hypothesis is that the performance of such novel algorithms implicitly provides an insight into the quality of the used ontologies and thus opens the way to a task-based evaluation of the Semantic Web. We have investigated this hypothesis by studying the lessons learnt about online ontologies when used to solve three tasks: ontology matching, folksonomy enrichment, and word sense disambiguation. Our analysis leads to a suit of conclusions about the status of the Semantic Web, which highlight a number of strengths and weaknesses of the semantic information available online and complement the findings of other analysis of the Semantic Web landscape."
http://videolectures.net/iswc07_gomez_odp/,"Design patterns are widely-used software engineering abstractions which define guidelines for modeling common application scenarios. Ontology design patterns are the extension of software patterns for knowledge acquisition in the Semantic Web. In this work we present a design pattern for representing relevance depending on context in OWL ontologies, i.e. to assert which knowledge from the domain ought to be considered in a given scenario. Besides the formal semantics and the features of the pattern, we describe a reasoning procedure to extract relevant knowledge in the resulting ontology and a plug-in for Prot´eg´e which assists pattern use."
http://videolectures.net/iswc07_besana_hscs/,"In open and distributed environments ontology mapping provides interoperability between interacting actors. However, conventional mapping systems focus on acquiring static information, and on mapping whole ontologies, which is infeasible in open systems. This paper shows that the interactions themselves between the actors can be used to predict mappings, simplifying dynamic ontology mapping. The intuitive idea is that similar interactions follow similar conventions and patterns, which can be analysed. The computed model can be used to suggest the possible mappings for the exchanged messages in new interactions. The suggestions can be evaluate by any standard ontology matcher: if they are accurate, the matchers avoid evaluating mappings unrelated to the interaction. The minimal requirement in order to use this system is that it is possible to describe and identify the interaction sequences: the OpenKnowledge project has produced an implementation that demonstrates this is possible in a fully peer-to-peer environment."
http://videolectures.net/iswc07_lambrix_mro/,"In different areas ontologies have been developed and many of these ontologies contain overlapping information. Often we would therefore want to be able to use multiple ontologies. To obtain good results, we need to find the relationships between terms in the different ontologies, i.e. we need to align them. Currently, there already exist a number of different alignment strategies. However, it is usually difficult for a user that needs to align two ontologies to decide which of the different available strategies are the most suitable. In this paper we propose a method that provides recommendations on alignment strategies for a given alignment problem. The method is based on the evaluation of the different available alignment strategies on several small selected pieces from the ontologies, and uses the evaluation results to provide recommendations. In the paper we give the basic steps of the method, and then illustrate and discuss the method in the setting of an alignment problem with two well-known biomedical ontologies. We also experiment with different implementations of the steps in the method."
http://videolectures.net/iswc07_schlobach_esib/,"Instance-based ontology mapping is a promising family of solutions to a class of ontology alignment problems. It crucially depends on measuring the similarity between sets of annotated instances. In this paper we study how the choice of co-occurrence measures affects the performance of instance-based mapping. To this end, we have implemented a number of different statistical cooccurrence measures. We have prepared an extensive test case using vocabularies of thousands of terms, millions of instances, and hundreds of thousands of co-annotated items. We have obtained a human Gold Standard judgement for part of the mapping-space. We then study how the different co-occurrence measures and a number of algorithmic variations perform on our benchmark dataset as compared against the Gold Standard. Our systematic study shows excellent results of instance-based match- ing in general, where the more simple measures often outperform more sophisticated statistical co-occurrence measures."
http://videolectures.net/iswc07_bloehdorn_kmmi/,"The amount of ontologies and meta data available on the Web is constantly growing. The successful application of machine learning techniques for learning of ontologies from textual data, i.e. mining for the Semantic Web, contributes to this trend. However, no principal approaches exist so far for mining from the Semantic Web. We investigate how machine learning algorithms can be made amenable for directly taking advantage of the rich knowledge expressed in ontologies and associated instance data. Kernel methods have been successfully employed in various learning tasks and provide a clean framework for interfacing between non-vectorial data and machine learning algorithms. In this spirit, we express the problem of mining instances in ontologies as the problem of defining valid corresponding kernels. We present a principled framework for designing such kernels by means of decomposing the kernel computation into specialized kernels for selected characteristics of an ontology which can be flexibly assembled and tuned. Initial experiments on real world Semantic Web data enjoy promising results and show the usefulness of our approach."
http://videolectures.net/iswc07_zhang_irash/,"As an extension to the current Web, Semantic Web will not only contain structured data with machine understandable semantics but also textual information. While structured queries can be used to find information more precisely on the Semantic Web, keyword searches are still needed to help exploit textual information. It thus becomes very important that we can combine precise structured queries with imprecise keyword searches to have a hybrid query capability. In addition, due to the huge volume of information on the Semantic Web, the hybrid query must be processed in a very scalable way. In this paper, we define such a hybrid query capability that combines unary tree-shaped structured queries with keyword searches. We show how existing information retrieval (IR) index structures and functions can be reused to index semantic web data and its textual information, and how the hybrid query is evaluated on the index structure using IR engines in an efficient and scalable manner. We implemented this IR approach in an engine called Semplore. Comprehensive experiments on its performance show that it is a promising approach. It leads us to believe that it may be possible to evolve current web search engines to query and search the Semantic Web. Finally, we breifly describe how Semplore is used for searching Wikipedia and an IBM customer’s product information."
http://videolectures.net/iswc07_funk_cloe/,"This paper presents a controlled language for ontology editing  and a software implementation, based partly on standard NLP tools,  for processing that language and manipulating an ontology. The input  sentences are analysed deterministically and compositionally with respect  to a given ontology, which the software consults in order to interpret  the input’s semantics; this allows the user to learn fewer syntactic  structures since some of them can be used to refer to either classes or  instances, for example. A repeated-measures, task-based evaluation has  been carried out in comparison with a well-known ontology editor; our  software received favourable results for basic tasks. The paper also discusses  work in progress and future plans for developing this language  and tool."
http://videolectures.net/iswc07_ciravegna_swt/,This invited tutorial will give an overview of the Semantic Web enabling conference attendees to better understand the technical presentations in the main conference and associated workshops. Building upon a series of week long Semantic Web summer schools which have been running successfully since 2003 (see http://knowledgeweb.semanticweb.org/sssw07) this tutorial brings together some of the key researchers in the area of the Semantic Web.
http://videolectures.net/iswc07_euzenat_si/,"In the same way that the Web is composed of heterogeneous resources the Semantic Web is composed of heterogeneous ontologies. In this session Jerome and Natasha will discuss what interoperability means at the semantic level. Additionally, they will outline different techniques which can be used to address this problem. At the end of this session attendees will understand the notions and issues underlying semantic interoperability."
http://videolectures.net/iswc07_calvanese_oda/,"In this tutorial we provide a comprehensive understanding of the  problem of ontology-based data access, from both the theoretical and  the practical points of view. We address several problems that are  crucial in this context, such as expressiveness/efficiency tradeoff,  query processing, impedance mismatch between ontology and data levels,  and integration of multiple data sources. We present solutions to these  problems based on recent research results in the area of tractable  Description Logics, and we provide also a ``hands-on'' experience with  QuOnto, a state-of-the-art system for ontology-based data access."
http://videolectures.net/iswc07_lembo_oda/,"In this tutorial we provide a comprehensive understanding of the  problem of ontology-based data access, from both the theoretical and  the practical points of view. We address several problems that are  crucial in this context, such as expressiveness/efficiency tradeoff,  query processing, impedance mismatch between ontology and data levels,  and integration of multiple data sources. We present solutions to these  problems based on recent research results in the area of tractable  Description Logics, and we provide also a ``hands-on'' experience with  QuOnto, a state-of-the-art system for ontology-based data access."
http://videolectures.net/iswc07_aasman_usn/,"Most of the attention in the Semantic Web world is currently focused on  using ontologies, rdfs and owl reasoning to get more value out of  enterprise data. Many enterprise databases are full of information  about people, companies, relationships between people and companies,  places and events. The Semantic Web literature also carries the promise  of analyzing networks of people, networks of companies and events in  time and space. This talk will show how Business Intelligence problems  can be solved with a combination of basic semantic web reasoning and  complementary techniques such as social network analysis and  geotemporal reasoning. We will be using AllegroGraph in this talk, but  the concepts learned will transfer to other Semantic Web solutions."
http://videolectures.net/iswc07_groza_wcw/,"In this paper we present a solution for “weaving the claim web”, i.e. the creation of knowledge networks via so-called claims stated in scientific publications created with the SALT (Semantically Annotated LATEX) framework. To attain this objective, we provide support for claim identification, evolved the appropriate ontologies and defined a claim citation and reference mechanism. We also describe a prototypical claim search engine, which allows to reference to existing claims and hence, weave the web. Finally, we performed a small-scale evaluation of the authoring framework with a quite promising outcome."
http://videolectures.net/iswc07_fu_mmw/,"Wikipedia, a killer application in Web 2.0, has embraced the power of collaborative editing to harness collective intelligence. It can also serve as an ideal Semantic Web data source due to its abundance, influence, high quality and well-structuring. However, the heavy burden of up-building and maintain-ing such an enormous and ever-growing online encyclopedic knowledge base still rests on a very small group of people. Many casual users may still feel dif-ficulties in writing high quality Wikipedia articles. In this paper, we use RDF graphs to model the key elements in Wikipedia authoring, and propose an inte-grated solution to make Wikipedia authoring easier based on RDF graph match-ing, expecting making more Wikipedians. Our solution facilitates semantics reuse and provides users with: 1) a link suggestion module that suggests and au-to-completes internal links between Wikipedia articles for the user; 2) a catego-ry suggestion module that helps the user place her articles in correct categories. A prototype system is implemented and experimental results show significant improvements over existing solutions to link and category suggestion tasks. The proposed enhancements can be applied to attract more contributors and relieve the burden of professional editors, thus enhancing the current Wikipedia to make it an even better Semantic Web data source."
http://videolectures.net/iswc07_tran_obi/,"Current information retrieval (IR) approaches do not formally capture the explicit meaning of a keyword query but provide a comfortable way for the user to specify information needs on the basis of keywords. Ontology-based approaches allow for sophisticated semantic search but impose a query syntax more difficult to handle. In this paper, we present an approach for translating keyword queries to DL conjunctive queries using background knowledge available in ontologies. We present an implementation which shows that this interpretation of keywords can then be used for both exploration of asserted knowledge and for a semantics-based declarative query answering process.We also present an evaluation of our system and a discussion of the limitations of the approach with respect to our underlying assumptions which directly points to issues for future work."
http://videolectures.net/iswc07_cumc_mpr/,"This talk describes a large case study that explores the applicability of ontology reasoning to problems in the medical domain. We investigate whether it is possible to use such reasoning to automate com- mon clinical tasks that are currently labor intensive and error prone, and focus our case study on improving cohort selection for clinical trials. An obstacle to automating such clinical tasks is the need to bridge the semantic gulf between raw patient data, such as laboratory tests or specific medications, and the way a clinician interprets this data. Our key insight is that matching patients to clinical trials can be formulated as a problem of semantic retrieval. We describe the technical challenges to building a realistic case study, which include problems related to scalability, the integration of large ontologies, and dealing with noisy, inconsistent data. Our solution is based on the SNOMED CT R&#160; ontology, and scales to one year of patient records (approx. 240,000 patients)."
http://videolectures.net/iswc07_falconer_csf/,"Ontology mapping is the key to data interoperability in the semantic  web. This problem has received a lot of research attention, however, the research  emphasis has been mostly devoted to automating the mapping process,  even though the creation of mappings often involve the user. As industry interest  in semantic web technologies grows and the number of widely adopted semantic  web applications increases, we must begin to support the user. In this paper, we  combine data gathered from background literature, theories of cognitive support  and decision making, and an observational case study to propose a theoretical  framework for cognitive support in ontology mapping tools. We also describe a  tool called COGZ that is based on this framework."
http://videolectures.net/iswc07_noll_wsp/,"In this talk, we present a new approach to web search personalization based on user collaboration and sharing of information about web documents. The proposed personalization technique separates data collection and user profiling from the information system whose contents and indexed documents are being searched for, i.e. the search engines, and uses social bookmarking and tagging to re-rank web search results. It is independent of the search engine being used, so users are free to choose the one they prefer, even if their favorite search engine does not natively support personalization. We show how to design and implement such a system in practice and investigate its feasibility and usefulness with large sets of real-word data and a user study."
http://videolectures.net/iswc07_martin_parai/,"We describe a novel approach by which software can assess  the ability of a confederation of heterogeneous systems to interoperate  to achieve a given purpose. The approach uses ontologies and knowledge  bases (KBs) to capture the salient characteristics of systems, on  the one hand, and of tasks for which these systems will be employed,  on the other. Rules are used to represent the conditions under which  the capabilities provided by systems can fulfill the capabilities needed to  support the roles and interactions that make up each task. An Analyzer  component employs these KBs and rules to determine if a given confederation  will be adequate, to generate suitable confederations from a  collection of available systems, to pre-diagnose potential interoperability  problems that might arise, and to suggest system configuration options  that will help to make interoperability possible. We have demonstrated  the feasibility of this approach using a prototype Analyzer and KBs."
http://videolectures.net/iswc07_funk_obie/,Business Intelligence (BI) requires the acquisition and aggregation  of key pieces of knowledge from multiple sources in order to  provide valuable information to customers or feed statistical BI models  and tools. The massive amount of information available to business  analysts makes information extraction and other natural language processing  tools key enablers for the acquisition and use of that semantic  information. We describe the application of ontology-based extraction  and merging in the context of a practical e-business application for the  EU MUSING Project where the goal is to gather international company  intelligence and country/region information. The results of our experiments  so far are very promising and we are now in the process of building  a complete end-to-end solution.
http://videolectures.net/iswc07_abel_eacd/,"Semantic Web databases allow efficient storage and access to  RDF statements. Applications are able to use expressive query languages  in order to retrieve relevant metadata to perform different tasks. However,  access to metadata may not be public to just any application or  service. Instead, powerful and flexible mechanisms for protecting sets of  RDF statements are required for many Semantic Web applications. Unfortunately,  current RDF stores do not provide fine-grained protection.  This paper fills this gap and presents a mechanism by which complex and  expressive policies can be specified in order to protect access to metadata  in multi-service environments."
http://videolectures.net/iswc07_namgoong_obcnl/,"In recent years, CNL (Controlled Natural Language) has received much attention with regard to ontology-based knowledge acquisition systems. CNLs, as subsets of natural languages, can be useful for both humans and computers by eliminating ambiguity of natural languages. Our previous work, OntoPath [10], proposed to edit natural language-like narratives that are structured in RDF (Resource Description Framework) triples, using a domain-specific ontology as their language constituents. However, our previous work and other systems employing CFG for grammar definition have difficulties in enlarging the expression capacity. A newly developed editor, which we propose in this paper, permits grammar definitions through CFG-LD (Context-Free Grammar with Lexical Dependency) that includes sequential and semantic structures of the grammars. With CFG describing the sequential structure of grammar, lexical dependencies between sentence elements can be designated in the definition system. Through the defined grammars, the implemented editor guides users’ narratives in more familiar expressions with a domain-specific ontology and translates the content into RDF triples."
http://videolectures.net/iswc07_kaufman_hunl/,"Natural language interfaces offer end-users a familiar and  convenient option for querying ontology-based knowledge bases. Several  studies have shown that they can achieve high retrieval performance as  well as domain independence. This paper focuses on usability and investigates  if NLIs are useful from an end-user’s point of view. To that end,  we introduce four interfaces each allowing a different query language and  present a usability study benchmarking these interfaces. The results of  the study reveal a clear preference for full sentences as query language  and confirm that NLIs are useful for querying Semantic Web data."
http://videolectures.net/iswc07_tran_lsa/,"Ontology-based applications play an increasingly important role in the public and corporate Semantic Web. While today there exist a range of tools and technologies to support specific ontology engineering and management activities, architectural design guidelines for building ontology-based applications are missing. In this paper, we present an architecture for ontology-based applications—covering the complete ontology-lifecycle—that is intended to support software engineers in designing and developing ontology-based applications. We illustrate the use of the architecture in a concrete case study using the NeOn toolkit as one implementation of the architecture."
http://videolectures.net/iswc07_troncy_dwfm/,"Semantic descriptions of non-textual media available on the web can be used to facilitate retrieval and presentation of media assets and documents containing them. While technologies for multimedia semantic descriptions already exist, there is as yet no formal description of a high quality multimedia ontology that is compatible with existing (semantic) web technologies. We explain the complexity of the problem using an annotation scenario. We then derive a number of requirements for specifying a formal multimedia ontology before we present the developed ontology, COMM, and evaluate it with respect to our requirements. We provide an API for generating multimedia annotations that conform to COMM."
http://videolectures.net/iswc07_yuzhong_dsmb/,"Ontologies proliferate with the growth of the Semantic Web. However, most of data on theWeb are still stored in relational databases. Therefore, it is important to establish interoperability between relational databases and ontologies for creating a Web of data. An e®ective way to achieve interoperability is ¯nding mappings between relational database schemas and ontologies. In this paper, we propose a new approach to discovering simple mappings between a relational database schema and an ontology. It exploits simple mappings based on virtual documents, and eliminates incorrect mappings via validating mapping consistency. Additionally, it also constructs a special type of semantic mappings, called contextual mappings, which is useful for practical applications. Experimental results demonstrate that our approach performs well on several data sets from real world domains."
http://videolectures.net/iswc07_ungrangsi_aca/,"Automatic knowledge reuse for Semantic Web applications imposes several challenges on ontology search. Existing ontology retrieval systems merely return a lengthy list of relevant single ontologies, which may not completely cover the specified user requirements. Therefore, there arises an increasing demand for a tool or algorithm with a mechanism to check concept adequacy of existing ontologies with respect to a user query, and then recommend a single or combination of ontologies which can entirely fulfill the requirements. Thus, this paper develops an algorithm, namely combiSQORE to determine whether the available collection of ontologies is able to completely satisfy a submitted query and return a single or combinative ontology that guarantees query coverage. In addition, it ranks the returned answers based on their conceptual closeness and query coverage. The experimental results show that the proposed algorithm is simple, efficient and effective."
http://videolectures.net/iswc07_liarou_crdf/,"We study the continuous evaluation of conjunctive triple pattern queries over RDF data stored in distributed hash tables. In a continuous query scenario network nodes subscribe with long-standing queries and receive answers whenever RDF triples satisfying their queries are published. We present two novel query processing algorithms for this scenario and analyze their properties formally. Our performance goal is to have algorithms that scale to large amounts of RDF data, distribute the storage and query processing load evenly and incur as little network traffic as possible. We discuss the various performance tradeoffs that occur through a detailed experimental evaluation of the proposed algorithms."
http://videolectures.net/iswc07_grobelnik_wsw/,"The tutorial will cover basic topics from the field of Machine Learning  explained in an intuitive way relevant for Semantic Web researchers and  practitioners. In the first part the topics will cover brief top level  overview of the Machine Learning field, its algorithms, and data types  being analyzed. In the second part we will cover relation to Semantic  Web and Web2.0. In the last part we will perform hands-on exercise with  some of the tools for modeling text semantics and social networks in  analytical way."
http://videolectures.net/iswc07_mladenic_wsw/,"The tutorial will cover basic topics from the field of Machine Learning  explained in an intuitive way relevant for Semantic Web researchers and  practitioners. In the first part the topics will cover brief top level  overview of the Machine Learning field, its algorithms, and data types  being analyzed. In the second part we will cover relation to Semantic  Web and Web2.0. In the last part we will perform hands-on exercise with  some of the tools for modeling text semantics and social networks in  analytical way."
http://videolectures.net/iswc07_fortuna_wsw/,"The tutorial will cover basic topics from the field of Machine Learning  explained in an intuitive way relevant for Semantic Web researchers and  practitioners. In the first part the topics will cover brief top level  overview of the Machine Learning field, its algorithms, and data types  being analyzed. In the second part we will cover relation to Semantic  Web and Web2.0. In the last part we will perform hands-on exercise with  some of the tools for modeling text semantics and social networks in  analytical way."
